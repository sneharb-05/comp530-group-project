{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Research question and objective\n",
        "The user will be prompted to input their research question and objective, from where we would get the necessary keywords and is also used to screen abstracts"
      ],
      "metadata": {
        "id": "SBK07kbERgIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEARCH PART\n",
        "\n",
        "Search strategy - Included all relevant papers with keyword extraction, and all the papers are downloaded. Once the papers are retrieved, they go through a screening process using abstracts, rank with respect to relevance."
      ],
      "metadata": {
        "id": "CptZCWFAQLvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJBYeKEM4W0x",
        "outputId": "112962e9-2a3f-41b2-f2da-4561d71b3733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "E8LcfubX4Z2M",
        "outputId": "a08200ef-e4ed-4a0c-d1f4-ec52dd6643c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f13fd55-6537-4506-8a30-def4194a81c6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7f13fd55-6537-4506-8a30-def4194a81c6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Semantic_key.env to Semantic_key.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EE8qum5QJHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab96351-df25-4031-d2b6-ef5ad846aa9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Welcome to the PRISMA-ScR Automated Research Tool!\n",
            "Enter keywords to search for research papers: How does AI improve medical diagnostics\n",
            "Searching PubMed, DOAJ, SEMANTIC SCHOLAR databases... Please wait...\n",
            "\n",
            "[Semantic Scholar] Rate-limited. Retrying in 1 seconds...\n",
            "[DOAJ] Response status: 200\n",
            "[Europe PMC] Response status: 200\n",
            "[Semantic Scholar] Rate-limited. Retrying in 2 seconds...\n",
            "[Semantic Scholar] Status: 200\n",
            "\n",
            "Downloading Paper 1: Rethinking sepsis: from controversy to precision-driven solutions.\n",
            "PDF downloaded: downloads/Rethinking_sepsis__from_controversy_to_precision-driven_solutions..pdf\n",
            "\n",
            "Downloading Paper 2: AI and Interventional Radiology: A Narrative Review of Reviews on Opportunities, Challenges, and Future Directions.\n",
            "PDF downloaded: downloads/AI_and_Interventional_Radiology__A_Narrative_Review_of_Reviews_on_Opportunities__Challenges__and_Fut.pdf\n",
            "\n",
            "Downloading Paper 3: Does Artificial Intelligence Bring New Insights in Diagnosing Phlebological Diseases?-A Systematic Review.\n",
            "PDF downloaded: downloads/Does_Artificial_Intelligence_Bring_New_Insights_in_Diagnosing_Phlebological_Diseases_-A_Systematic_R.pdf\n",
            "\n",
            "Downloading Paper 4: Proceedings of the Clinical Microbiology Open 2024: artificial intelligence applications in clinical microbiology.\n",
            "PDF downloaded: downloads/Proceedings_of_the_Clinical_Microbiology_Open_2024__artificial_intelligence_applications_in_clinical.pdf\n",
            "\n",
            "Downloading Paper 5: Artificial Intelligence in Relation to Accurate Information and Tasks in Gynecologic Oncology and Clinical Medicine-Dunning-Kruger Effects and Ultracrepidarianism.\n",
            "PDF downloaded: downloads/Artificial_Intelligence_in_Relation_to_Accurate_Information_and_Tasks_in_Gynecologic_Oncology_and_Cl.pdf\n",
            "\n",
            "Downloading Paper 6: AI-driven biomarker discovery: enhancing precision in cancer diagnosis and prognosis.\n",
            "PDF downloaded: downloads/AI-driven_biomarker_discovery__enhancing_precision_in_cancer_diagnosis_and_prognosis..pdf\n",
            "\n",
            "Downloading Paper 7: Harnessing the power of artificial intelligence for disease-surveillance purposes.\n",
            "PDF downloaded: downloads/Harnessing_the_power_of_artificial_intelligence_for_disease-surveillance_purposes..pdf\n",
            "\n",
            "Downloading Paper 8: Leveraging Artificial Intelligence in Breast Cancer Screening and Diagnosis.\n",
            "PDF downloaded: downloads/Leveraging_Artificial_Intelligence_in_Breast_Cancer_Screening_and_Diagnosis..pdf\n",
            "\n",
            "Downloading Paper 9: 'In the Midst of Every Crisis, Lies Great Opportunity': Perceptions of the Future Use of Artificial Intelligence in the UK NHS Primary Care.\n",
            "PDF downloaded: downloads/_In_the_Midst_of_Every_Crisis__Lies_Great_Opportunity___Perceptions_of_the_Future_Use_of_Artificial_.pdf\n",
            "\n",
            "Downloading Paper 10: Redefining disease in the age of blood-based biomarkers.\n",
            "PDF downloaded: downloads/Redefining_disease_in_the_age_of_blood-based_biomarkers..pdf\n",
            "\n",
            "Downloading Paper 11: Artificial Intelligence in Biomedical Engineering and Its Influence on Healthcare Structure: Current and Future Prospects.\n",
            "PDF downloaded: downloads/Artificial_Intelligence_in_Biomedical_Engineering_and_Its_Influence_on_Healthcare_Structure__Current.pdf\n",
            "\n",
            "Downloading Paper 12: Comparing ChatGPT 4.0's Performance in Interpreting Thyroid Nodule Ultrasound Reports Using ACR-TI-RADS 2017: Analysis Across Different Levels of Ultrasound User Experience.\n",
            "PDF downloaded: downloads/Comparing_ChatGPT_4.0_s_Performance_in_Interpreting_Thyroid_Nodule_Ultrasound_Reports_Using_ACR-TI-R.pdf\n",
            "\n",
            "Downloading Paper 13: A Systematic Integration of Artificial Intelligence Models in Appendicitis Management: A Comprehensive Review.\n",
            "PDF downloaded: downloads/A_Systematic_Integration_of_Artificial_Intelligence_Models_in_Appendicitis_Management__A_Comprehensi.pdf\n",
            "\n",
            "Downloading Paper 14: Future Perspectives in Radiology: Artificial Intelligence for Responsible Imaging (AIRI).\n",
            "PDF downloaded: downloads/Future_Perspectives_in_Radiology__Artificial_Intelligence_for_Responsible_Imaging__AIRI_..pdf\n",
            "\n",
            "Downloading Paper 15: AI-Driven Advances in Low-Dose Imaging and Enhancement-A Review.\n",
            "PDF downloaded: downloads/AI-Driven_Advances_in_Low-Dose_Imaging_and_Enhancement-A_Review..pdf\n",
            "\n",
            "Downloading Paper 16: Surveying the Digital Cytology Workflow in Italy: An Initial Report on AI Integration Across Key Professional Roles.\n",
            "PDF downloaded: downloads/Surveying_the_Digital_Cytology_Workflow_in_Italy__An_Initial_Report_on_AI_Integration_Across_Key_Pro.pdf\n",
            "\n",
            "Downloading Paper 17: Building health systems capable of leveraging AI: applying Paul Farmer's 5S framework for equitable global health.\n",
            "PDF downloaded: downloads/Building_health_systems_capable_of_leveraging_AI__applying_Paul_Farmer_s_5S_framework_for_equitable_.pdf\n",
            "\n",
            "Downloading Paper 18: Peer Review of “Large Language Models for Pediatric Differential Diagnoses in Rural Health Care: Multicenter Retrospective Cohort Study Comparing GPT-3 With Pediatrician Performance”\n",
            "PDF downloaded: downloads/Peer_Review_of__Large_Language_Models_for_Pediatric_Differential_Diagnoses_in_Rural_Health_Care__Mul.pdf\n",
            "\n",
            "Downloading Paper 19: Deep Learning Models to Detect Anterior Cruciate Ligament Injury on MRI: A Comprehensive Review.\n",
            "PDF downloaded: downloads/Deep_Learning_Models_to_Detect_Anterior_Cruciate_Ligament_Injury_on_MRI__A_Comprehensive_Review..pdf\n",
            "\n",
            "Downloading Paper 20: Artificial Intelligence in Gynecological Oncology from Diagnosis to Surgery.\n",
            "PDF downloaded: downloads/Artificial_Intelligence_in_Gynecological_Oncology_from_Diagnosis_to_Surgery..pdf\n",
            "\n",
            "Downloading Paper 21: Artificial Intelligence-Augmented Advancements in the Diagnostic Challenges Within Renal Cell Carcinoma.\n",
            "PDF downloaded: downloads/Artificial_Intelligence-Augmented_Advancements_in_the_Diagnostic_Challenges_Within_Renal_Cell_Carcin.pdf\n",
            "\n",
            "Downloading Paper 22: A Multimodal Deep Learning Model for the Classification of Breast Cancer Subtypes.\n",
            "PDF downloaded: downloads/A_Multimodal_Deep_Learning_Model_for_the_Classification_of_Breast_Cancer_Subtypes..pdf\n",
            "\n",
            "Downloading Paper 23: The AI Orthopedician will see you now - But who is Liable if it's Wrong?\n",
            "PDF downloaded: downloads/The_AI_Orthopedician_will_see_you_now_-_But_who_is_Liable_if_it_s_Wrong_.pdf\n",
            "\n",
            "Downloading Paper 24: Ethics of artificial intelligence in embryo assessment: mapping the terrain.\n",
            "PDF downloaded: downloads/Ethics_of_artificial_intelligence_in_embryo_assessment__mapping_the_terrain..pdf\n",
            "\n",
            "Downloading Paper 25: Advancing clinical biochemistry: addressing gaps and driving future innovations.\n",
            "PDF downloaded: downloads/Advancing_clinical_biochemistry__addressing_gaps_and_driving_future_innovations..pdf\n",
            "\n",
            "Downloading Paper 26: Artificial Intelligence as a Tool for Self-Care in Patients with Type 1 and Type 2 Diabetes-An Integrative Literature Review.\n",
            "PDF downloaded: downloads/Artificial_Intelligence_as_a_Tool_for_Self-Care_in_Patients_with_Type_1_and_Type_2_Diabetes-An_Integ.pdf\n",
            "\n",
            "Downloading Paper 27: Explainable Artificial Intelligence in Neuroimaging of Alzheimer's Disease.\n",
            "PDF downloaded: downloads/Explainable_Artificial_Intelligence_in_Neuroimaging_of_Alzheimer_s_Disease..pdf\n",
            "\n",
            "Downloading Paper 28: Advancing Diabetic Retinopathy Screening: A Systematic Review of Artificial Intelligence and Optical Coherence Tomography Angiography Innovations.\n",
            "PDF downloaded: downloads/Advancing_Diabetic_Retinopathy_Screening__A_Systematic_Review_of_Artificial_Intelligence_and_Optical.pdf\n",
            "\n",
            "Downloading Paper 29: Sustainable materials for artificial intelligence (AI) technology adoption for energy-efficient patient-centric healthcare solutions.\n",
            "PDF downloaded: downloads/Sustainable_materials_for_artificial_intelligence__AI__technology_adoption_for_energy-efficient_pati.pdf\n",
            "\n",
            "Downloading Paper 30: Authors’ Response to Peer Reviews of “Large Language Models for Pediatric Differential Diagnoses in Rural Health Care: Multicenter Retrospective Cohort Study Comparing GPT-3 With Pediatrician Performance”\n",
            "PDF downloaded: downloads/Authors__Response_to_Peer_Reviews_of__Large_Language_Models_for_Pediatric_Differential_Diagnoses_in_.pdf\n",
            "\n",
            "Downloading Paper 31: Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives\n",
            "PDF downloaded: downloads/Use_of_AI-based_tools_for_healthcare_purposes__a_survey_study_from_consumers__perspectives.pdf\n",
            "\n",
            "Downloading Paper 32: HTLML: Hybrid AI Based Model for Detection of Alzheimer’s Disease\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/12/8/1833/pdf?version=1659435579\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 33: Embracing AI: The Imperative Tool for Echo Labs to Stay Ahead of the Curve\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/13/19/3137/pdf?version=1696571266\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 34: Features of Mobile Apps for People with Autism in a Post COVID-19 Scenario: Current Status and Recommendations for Apps Using AI\n",
            "Using Unpaywall for DOI: 10.3390/diagnostics11101923\n",
            "Scraping HTML for PDF: https://doi.org/10.3390/diagnostics11101923\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 35: Prevent Medical Errors through Artificial Intelligence: A Review\n",
            "PDF downloaded: downloads/Prevent_Medical_Errors_through_Artificial_Intelligence__A_Review.pdf\n",
            "\n",
            "Downloading Paper 36: Artificial intelligence and machine learning in precision and genomic medicine\n",
            "Scraping HTML for PDF: https://link.springer.com/content/pdf/10.1007/s12032-022-01711-1.pdf\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 37: Advances in Ultrasound-Guided Surgery and Artificial Intelligence Applications in Musculoskeletal Diseases\n",
            "Using Unpaywall for DOI: 10.3390/diagnostics14182008\n",
            "Scraping HTML for PDF: https://doi.org/10.3390/diagnostics14182008\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 38: Impact of Image Resolution on Deep Learning Performance in Endoscopy Image Classification: An Experimental Study Using a Large Dataset of Endoscopic Images\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/11/12/2183/pdf?version=1637762975\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 39: Artificial Intelligence-Assisted Chest X-ray for the Diagnosis of COVID-19: A Systematic Review and Meta-Analysis\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/13/4/584/pdf?version=1675579309\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 40: Recent Advances in the Field of Artificial Intelligence for Precision Medicine in Patients with a Diagnosis of Metastatic Cutaneous Melanoma\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/13/22/3483/pdf?version=1700485259\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 41: Forecasting Patient Early Readmission from Irish Hospital Discharge Records Using Conventional Machine Learning Models\n",
            "Using Unpaywall for DOI: 10.3390/diagnostics14212405\n",
            "Scraping HTML for PDF: https://doi.org/10.3390/diagnostics14212405\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 42: Evolution of research and development in the field of artificial intelligence technologies for healthcare in the Russian Federation: results of 2021\n",
            "PDF downloaded: downloads/Evolution_of_research_and_development_in_the_field_of_artificial_intelligence_technologies_for_healt.pdf\n",
            "\n",
            "Downloading Paper 43: Combining External Medical Knowledge for Improving Obstetric Intelligent Diagnosis: Model Development and Validation\n",
            "PDF downloaded: downloads/Combining_External_Medical_Knowledge_for_Improving_Obstetric_Intelligent_Diagnosis__Model_Developmen.pdf\n",
            "\n",
            "Downloading Paper 44: Cancer: A Computational Disease that AI Can Cure\n",
            "PDF downloaded: downloads/Cancer__A_Computational_Disease_that_AI_Can_Cure.pdf\n",
            "\n",
            "Downloading Paper 45: Combined Artificial Intelligence Approaches Analyzing 1000 Conservative Patients with Back Pain—A Methodological Pathway to Predicting Treatment Efficacy and Diagnostic Groups\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/11/11/1934/pdf?version=1634691458\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 46: Artificial intelligence and machine learning in haematology\n",
            "Scraping HTML for PDF: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjh.15774\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 47: Methodology for testing and monitoring AI-based software for medical diagnostics\n",
            "Scraping HTML for PDF: https://jdigitaldiagnostics.com/DD/article/download/321971/pdf\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 48: Augmenting Radiological Diagnostics with AI for Tuberculosis and COVID-19 Disease Detection: Deep Learning Detection of Chest Radiographs\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/14/13/1334/pdf?version=1719222051\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 49: Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study\n",
            "PDF downloaded: downloads/Adoption_of_Machine_Learning_Systems_for_Medical_Diagnostics_in_Clinics__Qualitative_Interview_Study.pdf\n",
            "\n",
            "Downloading Paper 50: Improve the efficiency and accuracy of ophthalmologists’ clinical decision-making based on AI technology\n",
            "Using Unpaywall for DOI: 10.1186/s12911-024-02587-z\n",
            "Scraping HTML for PDF: https://doi.org/10.1186/s12911-024-02587-z\n",
            "PDF downloaded: downloads/Improve_the_efficiency_and_accuracy_of_ophthalmologists__clinical_decision-making_based_on_AI_techno.pdf\n",
            "\n",
            "Downloading Paper 51: Generative AI in Undergraduate Medical Education: A Rapid Review\n",
            "Scraping HTML for PDF: https://journals.sagepub.com/doi/pdf/10.1177/23821205241266697\n",
            "No downloadable PDF found\n",
            "\n",
            "Downloading Paper 52: Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\n",
            "Scraping HTML for PDF: https://www.mdpi.com/2075-4418/10/11/972/pdf\n",
            "No downloadable PDF found\n",
            "Search complete!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os, time\n",
        "import concurrent.futures\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Function to retreive fulltext url / doi url from DOAJ API response\n",
        "def get_fulltext_from_bibjson(bibjson):\n",
        "    # First try to get fulltext link from DOAJ metadata\n",
        "    for link in bibjson.get(\"link\", []):\n",
        "        if link.get(\"type\") == \"fulltext\":\n",
        "            return link.get(\"url\")\n",
        "\n",
        "    # If full text url not available, build fulltext landing page from DOI (redirects to publisher)\n",
        "    for id_obj in bibjson.get(\"identifier\", []):\n",
        "        if id_obj.get(\"type\") == \"doi\":\n",
        "            return f\"https://doi.org/{id_obj.get('id')}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# Function to search DOAJ DB\n",
        "def doaj_search(query, page_size=10):\n",
        "    url = f\"https://doaj.org/api/v2/search/articles/{query}?pageSize={page_size}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    print(f\"[DOAJ] Response status: {response.status_code}\")\n",
        "    papers = []\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        for result in data.get(\"results\", []):\n",
        "            bibjson = result.get(\"bibjson\", {})\n",
        "            title = bibjson.get(\"title\", \"N/A\")\n",
        "            abstract = bibjson.get(\"abstract\", \"\")\n",
        "            full_text_url = get_fulltext_from_bibjson(bibjson)\n",
        "\n",
        "            papers.append({\n",
        "                \"source\": \"DOAJ\",\n",
        "                \"title\": title,\n",
        "                \"abstract\": abstract,\n",
        "                \"full_text_url\": full_text_url\n",
        "            })\n",
        "    return papers\n",
        "\n",
        "# Function to search EuropePMC DB\n",
        "def europe_pmc_search(query, max_results=30):\n",
        "    params = {\"query\": query + \" + OPEN_ACCESS:Y\", \"format\": \"json\", \"pageSize\": max_results}\n",
        "    url = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
        "    response = requests.get(url, params=params)\n",
        "    print(f\"[Europe PMC] Response status: {response.status_code}\")\n",
        "    papers = []\n",
        "    if response.status_code == 200:\n",
        "        data = response.json().get(\"resultList\", {}).get(\"result\", [])\n",
        "        for item in data:\n",
        "            papers.append({\n",
        "                \"source\": \"Europe PMC\",\n",
        "                \"title\": item.get('title', 'N/A'),\n",
        "                \"abstract\": item.get('abstractText', ''),\n",
        "                \"link\": f\"https://europepmc.org/article/{item.get('source', '')}/{item.get('id', '')}\",\n",
        "                \"full_text_url\": f\"https://europepmc.org/backend/ptpmcrender.fcgi?accid={item.get('pmcid', '')}&blobtype=pdf\"\n",
        "            })\n",
        "    return papers\n",
        "\n",
        "# Function to search semantic scholar DB\n",
        "load_dotenv()\n",
        "\n",
        "def search_semantic_scholar(query, max_results=25):\n",
        "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "\n",
        "    # Load the API key from the environment variable\n",
        "    API_KEY = os.getenv(\"API_KEY\")\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"fields\": \"title,abstract,url,openAccessPdf\",  # Fields you want to retrieve\n",
        "        \"limit\": max_results  # Number of results to return\n",
        "    }\n",
        "\n",
        "    # Retry logic for rate-limiting (HTTP status 429)\n",
        "    retries = 10\n",
        "    for attempt in range(retries):\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "        # If the request is successful (status 200), process the response\n",
        "        if response.status_code == 200:\n",
        "            print(f\"[Semantic Scholar] Status: {response.status_code}\")\n",
        "            open_access_papers = []\n",
        "            results = response.json().get(\"data\", [])\n",
        "            for paper in results:\n",
        "                if paper.get(\"openAccessPdf\") and paper[\"openAccessPdf\"].get(\"url\"):\n",
        "                    open_access_papers.append({\n",
        "                        \"source\": \"Semantic Scholar\",\n",
        "                        \"title\": paper.get(\"title\"),\n",
        "                        \"abstract\": paper.get(\"abstract\", \"\"),\n",
        "                        \"full_text_url\": paper[\"openAccessPdf\"][\"url\"]\n",
        "                    })\n",
        "            return open_access_papers\n",
        "\n",
        "        # If rate-limited, back off and retry after a delay\n",
        "        elif response.status_code == 429:\n",
        "            print(f\"[Semantic Scholar] Rate-limited. Retrying in {2 ** attempt} seconds...\")\n",
        "            time.sleep(2 ** attempt)  # Exponential backoff\n",
        "        else:\n",
        "            print(f\"[Semantic Scholar] Error: {response.status_code}\")\n",
        "            break  # Exit on other errors like 4xx, 5xx\n",
        "\n",
        "    # If we exhausted retries and still getting rate-limited\n",
        "    return []\n",
        "\n",
        "# Function to perform parallel search on EuropePMC, DOAJ & Semantic Scholar APIs\n",
        "def parallel_search(query, max_results=30):\n",
        "    results = {\"EUROPEPMC\": [], \"DOAJ\": [], \"SEMANTIC\" : []}\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        future_pubmed = executor.submit(europe_pmc_search, query, max_results)\n",
        "        future_doaj = executor.submit(doaj_search, query, max_results)\n",
        "        future_semantic = executor.submit(search_semantic_scholar, query, max_results)\n",
        "\n",
        "        results[\"EUROPEPMC\"] = future_pubmed.result()\n",
        "        results[\"DOAJ\"] = future_doaj.result()\n",
        "        results[\"SEMANTIC\"] = future_semantic.result()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to check if full text url is a direct pdf link\n",
        "def is_direct_pdf_link(url):\n",
        "    try:\n",
        "        response = requests.head(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, allow_redirects=True, timeout=10)\n",
        "        return 'application/pdf' in response.headers.get(\"Content-Type\", \"\").lower()\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Function used to get pdf link from unpaywall if only doi is available\n",
        "def get_pdf_from_unpaywall(doi, email=\"your_email@example.com\"):\n",
        "    api_url = f\"https://api.unpaywall.org/v2/{doi}?email={email}\"\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            oa_location = data.get(\"best_oa_location\")\n",
        "            if oa_location and oa_location.get(\"url_for_pdf\"):\n",
        "                return oa_location[\"url_for_pdf\"]\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# Function to find pdf link if the full text url is pointing to a webpage instead of direct link\n",
        "def extract_pdf_link_from_html_page(page_url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    try:\n",
        "        response = requests.get(page_url, headers=headers, timeout=10)\n",
        "        if response.status_code != 200:\n",
        "            return None\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        for link in soup.find_all(\"a\", href=True):\n",
        "            classes = link.get(\"class\", [])\n",
        "            href = link[\"href\"]\n",
        "\n",
        "            # Match if any class contains 'pdf' or class list includes 'pdf'\n",
        "            if \"pdf\" in href.lower() or any(\"pdf\" in cls.lower() for cls in classes):\n",
        "                full_link = urljoin(page_url, href)\n",
        "                if full_link.endswith(\".pdf\") or \"view\" in full_link:  # customize as needed\n",
        "                    return full_link\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# Function to download the pdf to local if the url is a direct link\n",
        "def download_pdf_from_url(pdf_url, save_path=\"paper.pdf\"):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    try:\n",
        "        response = requests.get(pdf_url, headers=headers, stream=True, timeout=10)\n",
        "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
        "\n",
        "        if response.status_code == 200 and 'application/pdf' in content_type:\n",
        "            with open(save_path, \"wb\") as f:\n",
        "                for chunk in response.iter_content(1024):\n",
        "                    f.write(chunk)\n",
        "            print(f\"PDF downloaded: {save_path}\")\n",
        "            return save_path\n",
        "        else:\n",
        "            print(f\"Skipped (Not a PDF or blocked): {pdf_url} [Content-Type: {content_type}]\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading PDF from {pdf_url}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Function to rename the downloaded file based on title of the paper\n",
        "def sanitize_filename(title, version=\"\"):\n",
        "    return \"\".join(c if c.isalnum() or c in \"._-\" else \"_\" for c in title)[:100] + (f\"_{version}\" if version else \"\")\n",
        "\n",
        "# Function to download the papers after checking if it is a direct link/doi/webpage\n",
        "def download_all_pdfs(results):\n",
        "    os.makedirs(\"downloads\", exist_ok=True)\n",
        "    all_papers = results[\"EUROPEPMC\"] + results[\"DOAJ\"] + results[\"SEMANTIC\"]\n",
        "\n",
        "    for idx, paper in enumerate(all_papers):\n",
        "        title = paper.get(\"title\", f\"paper_{idx}\")\n",
        "        pdf_url = paper.get(\"full_text_url\")\n",
        "\n",
        "        if pdf_url:\n",
        "            filename = sanitize_filename(title) + \".pdf\"\n",
        "            save_path = os.path.join(\"downloads\", filename)\n",
        "            print(f\"\\nDownloading Paper {idx + 1}: {title}\")\n",
        "            resolve_pdf_url_and_download(pdf_url, save_path)\n",
        "\n",
        "# Function to resolve the pdf url correctly based on api response and download the paper accordingly\n",
        "def resolve_pdf_url_and_download(full_text_url, save_path):\n",
        "\n",
        "    # Direct PDF check\n",
        "    if is_direct_pdf_link(full_text_url):\n",
        "        return download_pdf_from_url(full_text_url, save_path)\n",
        "\n",
        "    # Check if link is DOI and use Unpaywall to download\n",
        "    parsed = urlparse(full_text_url)\n",
        "    if \"doi.org\" in parsed.netloc:\n",
        "        doi = parsed.path.strip(\"/\")\n",
        "        print(f\"Using Unpaywall for DOI: {doi}\")\n",
        "        pdf_url = get_pdf_from_unpaywall(doi)\n",
        "        if pdf_url and is_direct_pdf_link(pdf_url):\n",
        "            return download_pdf_from_url(pdf_url, save_path)\n",
        "\n",
        "    # Scrape the webpage to find PDF url and download\n",
        "    print(f\"Scraping HTML for PDF: {full_text_url}\")\n",
        "    pdf_url = extract_pdf_link_from_html_page(full_text_url)\n",
        "    if pdf_url and is_direct_pdf_link(pdf_url):\n",
        "        return download_pdf_from_url(pdf_url, save_path)\n",
        "\n",
        "    print(f\"No downloadable PDF found\")\n",
        "    return\n",
        "\n",
        "print(\"\\n Welcome to the PRISMA-ScR Automated Research Tool!\")\n",
        "query = input(\"Enter keywords to search for research papers: \")\n",
        "\n",
        "print(\"Searching PubMed, DOAJ, SEMANTIC SCHOLAR databases... Please wait...\\n\")\n",
        "search_results = parallel_search(query, max_results=30)\n",
        "\n",
        "download_all_pdfs(search_results)\n",
        "print(\"Search complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No reference query - How does AI improve medical diagnostics\n",
        "\n",
        "---\n",
        "\n",
        "RQ | No of papers in search | Initial versus final ranking (more comprehensive) | F-Score for summaries"
      ],
      "metadata": {
        "id": "O5wWuYWlUyK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble model\n",
        "The code uses multiple language models (Gemini and Mistral) to evaluate research papers based on their abstracts, rank them by relevance to a research question, and generate comprehensive summaries. By combining results from multiple models, we aim to produce more robust and accurate outputs than any single model alone.\n",
        "\n",
        "#Setup Instructions\n",
        "To use this code, you'll need:\n",
        "\n",
        "*   API keys for Gemini and Mistral models\n",
        "\n",
        "you can use the .env file approach:\n",
        "```\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('Semantic_key.env')\n",
        "```\n",
        "How ensemble model works:\n",
        "\n",
        "\n",
        "\n",
        "*   Paper Ranking: Each model ranks papers based on their relevance to a research question\n",
        "*   Ensemble Ranking: Rankings are combined to create a consensus ranking\n",
        "*   Summarization: The top-ranked papers are summarized individually and collectively\n",
        "*   Ensemble Summary: Model summaries are synthesized into a final summary\n",
        "*   Evaluation: Summaries are evaluated using BERT Score against reference summaries\n"
      ],
      "metadata": {
        "id": "1CcXkQDCXbV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD API KEYS TO RUN LLM APIs\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('Semantic_key.env')\n",
        "\n",
        "# Example format for your Semantic_key.env file:\n",
        "# GEMINI_API_KEY=your_gemini_api_key_here\n",
        "# MISTRAL_API_KEY=your_mistral_api_key_here\n",
        "\n",
        "# Test that keys are loaded properly\n",
        "print(\"API keys loaded successfully\" if os.environ.get(\"GEMINI_API_KEY\") and os.environ.get(\"MISTRAL_API_KEY\") else \"Failed to load API keys\")"
      ],
      "metadata": {
        "id": "P1Pfah7doN0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score mistralai"
      ],
      "metadata": {
        "id": "__B3W8O2dbr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1db908e-9a10-49a5-b6f8-937576ef71f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting mistralai\n",
            "  Downloading mistralai-1.7.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistralai-1.7.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.5/301.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, eval-type-backport, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mistralai, bert-score\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bert-score-0.3.13 eval-type-backport-0.2.2 mistralai-1.7.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import torch\n",
        "import os\n",
        "from google import genai\n",
        "from bert_score import score as bert_score\n",
        "from mistralai import Mistral\n",
        "\n",
        "def query_gemini(prompt, api_key):\n",
        "    \"\"\"\n",
        "    Send a prompt to the Gemini API and get a text response\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The text prompt to send to Gemini\n",
        "        api_key (str): The Gemini API key\n",
        "\n",
        "    Returns:\n",
        "        str or None: The text response from Gemini, or None if there was an error\n",
        "    \"\"\"\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "          model=\"gemini-2.0-flash\", contents=prompt\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying Gemini API: {e}\")\n",
        "        return None\n",
        "\n",
        "def query_mistral(prompt, api_token):\n",
        "    \"\"\"\n",
        "    Send a prompt to the Mistral API and get a response (attempts to parse as JSON)\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The text prompt to send to Mistral\n",
        "        api_token (str): The Mistral API token\n",
        "\n",
        "    Returns:\n",
        "        dict or str or None: JSON response if valid, raw text otherwise, or None if there was an error\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = \"mistral-small-latest\"\n",
        "        print(\"Sending prompt to Mistral API...\")\n",
        "        client = Mistral(api_key=api_token)\n",
        "        chat_response = client.chat.complete(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt,\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        response_content = chat_response.choices[0].message.content\n",
        "\n",
        "        # Try to parse as JSON\n",
        "        try:\n",
        "            json_response = json.loads(response_content)\n",
        "            return json_response\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Warning: Response is not valid JSON. Returning raw text.\")\n",
        "            return response_content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying Mistral API: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_ranking_response(response_text):\n",
        "    \"\"\"\n",
        "    Parse the ranking response from a language model\n",
        "\n",
        "    Args:\n",
        "        response_text (str): The raw text response from the model\n",
        "\n",
        "    Returns:\n",
        "        tuple: (ranking list, scores list) or (None, []) if parsing failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Try to extract JSON from the response\n",
        "        start_idx = response_text.find('{')\n",
        "        end_idx = response_text.rfind('}')\n",
        "\n",
        "        if start_idx >= 0 and end_idx > start_idx:\n",
        "            json_str = response_text[start_idx:end_idx+1]\n",
        "            ranking_data = json.loads(json_str)\n",
        "\n",
        "            if isinstance(ranking_data, dict) and \"ranking\" in ranking_data:\n",
        "                return ranking_data[\"ranking\"], ranking_data.get(\"scores\", [])\n",
        "\n",
        "        # Fallback to parsing numbered list\n",
        "        lines = response_text.strip().split('\\n')\n",
        "        ranking = []\n",
        "\n",
        "        for line in lines:\n",
        "            if line and ':' in line:\n",
        "                parts = line.split(':', 1)\n",
        "                try:\n",
        "                    index = int(parts[0].strip().rstrip('.')) - 1\n",
        "                    ranking.append(index)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "        return ranking, [] if ranking else None, []\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing ranking response: {e}\")\n",
        "        return None, []\n",
        "\n",
        "def get_model_rankings(abstracts, titles, query, gemini_api_key, hf_api_token):\n",
        "    \"\"\"\n",
        "    Get rankings of abstracts from both Gemini and Mistral models\n",
        "\n",
        "    Args:\n",
        "        abstracts (list): List of paper abstracts\n",
        "        titles (list): List of paper titles\n",
        "        query (str): The research question\n",
        "        gemini_api_key (str): Gemini API key\n",
        "        hf_api_token (str): Mistral API token\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing rankings and scores from both models\n",
        "    \"\"\"\n",
        "    abstract_list = \"\"\n",
        "    for i, abs in enumerate(abstracts):\n",
        "        abstract_list += f\"{i+1}. {abs}\\n\"  # If abs is a string. Adjust if dict.\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "      You are a research assistant helping with a scoping review.\n",
        "\n",
        "      RESEARCH QUESTION: {query}\n",
        "\n",
        "      I have retrieved the following {len(abstracts)} papers. Please rank them based on their relevance to the research question:\n",
        "\n",
        "      {abstract_list}\n",
        "\n",
        "      Based on their abstracts, rank these papers in order of relevance to my research question.\n",
        "      For each paper, assign a relevance score from 0 to 10, where 10 is most relevant.\n",
        "\n",
        "      Return your answer as a JSON object with the following format:\n",
        "      {{\n",
        "        \"ranking\": [list of paper numbers in order of relevance from most to least relevant],\n",
        "        \"scores\": [corresponding relevance scores for each paper]\n",
        "      }}\n",
        "\n",
        "      Provide ONLY the JSON response with no additional text.\n",
        "      \"\"\"\n",
        "    gemini_response = query_gemini(prompt, gemini_api_key)\n",
        "    mistral_response = query_mistral(prompt, hf_api_token)\n",
        "    gemini_ranking, gemini_scores = parse_ranking_response(gemini_response) if gemini_response else (None, [])\n",
        "    mistral_ranking, mistral_scores = parse_ranking_response(mistral_response) if mistral_response else (None, [])\n",
        "\n",
        "    results = {\n",
        "        \"gemini\": {\n",
        "            \"ranking\": gemini_ranking if gemini_ranking else [],\n",
        "            \"scores\": gemini_scores if gemini_scores else []\n",
        "        },\n",
        "        \"mistral\": {\n",
        "            \"ranking\": mistral_ranking if mistral_ranking else [],\n",
        "            \"scores\": mistral_scores if mistral_scores else []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_ensemble_ranking(abstracts, titles, query, results_from_models=None):\n",
        "    \"\"\"\n",
        "    Create an ensemble ranking by combining rankings from multiple models\n",
        "\n",
        "    Args:\n",
        "        abstracts (list): List of paper abstracts\n",
        "        titles (list): List of paper titles\n",
        "        query (str): The research question\n",
        "        results_from_models (dict, optional): Pre-computed model rankings\n",
        "\n",
        "    Returns:\n",
        "        tuple: (ensemble_ranked, ensemble_scores) where ensemble_ranked is an array of indices\n",
        "               ranked by relevance and ensemble_scores are their corresponding scores\n",
        "    \"\"\"\n",
        "    if not abstracts:\n",
        "        return np.arange(len(abstracts)), np.zeros(len(abstracts))\n",
        "\n",
        "    if results_from_models is None:\n",
        "        # Get API keys from environment variables\n",
        "        gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "        hf_api_token = os.environ.get(\"MISTRAL_API_KEY\")\n",
        "        results_from_models = get_model_rankings(abstracts, titles, query, gemini_api_key, hf_api_token)\n",
        "\n",
        "    gemini_ranking = np.array(results_from_models[\"gemini\"][\"ranking\"]) if results_from_models[\"gemini\"][\"ranking\"] else np.arange(len(abstracts))\n",
        "    mistral_ranking = np.array(results_from_models[\"mistral\"][\"ranking\"]) if results_from_models[\"mistral\"][\"ranking\"] else np.arange(len(abstracts))\n",
        "\n",
        "    # Ensure rankings are the correct length\n",
        "    if len(gemini_ranking) != len(abstracts):\n",
        "        gemini_ranking = np.arange(len(abstracts))\n",
        "    if len(mistral_ranking) != len(abstracts):\n",
        "        mistral_ranking = np.arange(len(abstracts))\n",
        "\n",
        "    # Calculate ensemble scores based on average position in the rankings\n",
        "    ensemble_scores = np.zeros(len(abstracts))\n",
        "    for i in range(len(abstracts)):\n",
        "        gemini_position = np.where(gemini_ranking == i)[0][0] if i in gemini_ranking else len(abstracts)\n",
        "        mistral_position = np.where(mistral_ranking == i)[0][0] if i in mistral_ranking else len(abstracts)\n",
        "\n",
        "        # Use inverse of average position as the score (lower position = higher score)\n",
        "        ensemble_scores[i] = 1 / (1 + (gemini_position + mistral_position) / 2)\n",
        "\n",
        "    # Sort by score in descending order\n",
        "    ensemble_ranked = np.argsort(ensemble_scores)[::-1]\n",
        "\n",
        "    return ensemble_ranked, ensemble_scores\n",
        "\n",
        "def get_model_summaries(abstracts, titles, ranking, query, gemini_api_key, hf_api_token, top_n=5):\n",
        "    \"\"\"\n",
        "    Generate summaries from both models for the top-ranked papers\n",
        "\n",
        "    Args:\n",
        "        abstracts (list): List of paper abstracts\n",
        "        titles (list): List of paper titles\n",
        "        ranking (list): List of paper indices in order of relevance\n",
        "        query (str): The research question\n",
        "        gemini_api_key (str): Gemini API key\n",
        "        hf_api_token (str): Mistral API token\n",
        "        top_n (int): Number of top papers to include in the summary\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing summaries from both models\n",
        "    \"\"\"\n",
        "    # Get the top n paper indices\n",
        "    top_indices = ranking[:min(top_n, len(ranking))]\n",
        "\n",
        "    # Format paper information for the prompt\n",
        "    papers_info = []\n",
        "    for i, idx in enumerate(top_indices):\n",
        "        paper_info = f\"{i+1}: \\\"{titles[idx]}\\\"\\n\"\n",
        "        paper_info += f\"Abstract: {abstracts[idx]}\\n\"\n",
        "        papers_info.append(paper_info)\n",
        "\n",
        "    papers_text = \"\\n\\n\".join(papers_info)\n",
        "\n",
        "    # Create the prompt for the summaries\n",
        "    prompt = f\"\"\"\n",
        "    You are a research assistant helping with a scoping review, following PRISMA Guidelines.\n",
        "    RESEARCH QUESTION: {query}\n",
        "    Based on the top {len(top_indices)} papers below, create a comprehensive summary that:\n",
        "    1. Identifies key themes and findings across the papers\n",
        "    2. Highlights methodological approaches used\n",
        "    3. Notes any gaps in the literature\n",
        "    4. Suggests directions for future research\n",
        "    Papers:\n",
        "    {papers_text}\n",
        "    Provide ONLY a well-structured summary that synthesizes the information from these papers with no additional text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get summaries from both models\n",
        "    gemini_summary = query_gemini(prompt, gemini_api_key)\n",
        "    mistral_summary = query_mistral(prompt, hf_api_token)\n",
        "\n",
        "    return {\n",
        "        \"gemini\": gemini_summary,\n",
        "        \"mistral\": mistral_summary\n",
        "    }\n",
        "\n",
        "def get_ensemble_summaries(abstracts, titles, query, results_from_models=None):\n",
        "    \"\"\"\n",
        "    Create an ensemble summary by combining summaries from multiple models\n",
        "\n",
        "    Args:\n",
        "        abstracts (list): List of paper abstracts\n",
        "        titles (list): List of paper titles\n",
        "        query (str): The research question\n",
        "        results_from_models (dict, optional): Pre-computed model rankings\n",
        "\n",
        "    Returns:\n",
        "        str: The ensemble summary text\n",
        "    \"\"\"\n",
        "    if not abstracts:\n",
        "        return \"No abstracts provided for summarization.\"\n",
        "\n",
        "    # Get the ensemble ranking\n",
        "    ensemble_ranked, _ = get_ensemble_ranking(abstracts, titles, query, results_from_models)\n",
        "\n",
        "    # Get API keys from environment variables\n",
        "    gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    hf_api_token = os.environ.get(\"MISTRAL_API_KEY\")\n",
        "\n",
        "    # Get summaries from both models\n",
        "    summaries = get_model_summaries(abstracts, titles, ensemble_ranked, query, gemini_api_key, hf_api_token)\n",
        "\n",
        "    # Create an ensemble summary if both model summaries exist\n",
        "    if summaries[\"gemini\"] and summaries[\"mistral\"]:\n",
        "        ensemble_prompt = f\"\"\"\n",
        "        You are a research assistant helping with a scoping review, following PRISMA guidelines.\n",
        "\n",
        "        I have two summaries of the same set of papers related to this research question: \"{query}\"\n",
        "\n",
        "        Summary 1:\n",
        "        {summaries[\"gemini\"]}\n",
        "\n",
        "        Summary 2:\n",
        "        {summaries[\"mistral\"]}\n",
        "\n",
        "        Please create a synthesis of these two summaries, incorporating the strongest insights and analysis from each.\n",
        "        The final summary should be comprehensive yet concise, highlighting key themes, methods, gaps, and future directions.\n",
        "        Do not reference these summaries and just output the final summary.\n",
        "        \"\"\"\n",
        "\n",
        "        ensemble_summary = query_gemini(ensemble_prompt, gemini_api_key)\n",
        "        return ensemble_summary\n",
        "    elif summaries[\"gemini\"]:\n",
        "        return summaries[\"gemini\"]\n",
        "    elif summaries[\"mistral\"]:\n",
        "        return summaries[\"mistral\"]\n",
        "    else:\n",
        "        return \"Unable to generate summaries from the provided models.\"\n",
        "\n",
        "def get_model_summaries_for_each_paper(abstracts, titles, query, gemini_api_key, hf_api_token):\n",
        "    \"\"\"\n",
        "    Generate individual summaries for each paper from both models\n",
        "\n",
        "    Args:\n",
        "        abstracts (list): List of paper abstracts\n",
        "        titles (list): List of paper titles\n",
        "        query (str): The research question\n",
        "        gemini_api_key (str): Gemini API key\n",
        "        hf_api_token (str): Mistral API token\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing combined summaries from both models\n",
        "    \"\"\"\n",
        "    gemini_summary = \"\"\n",
        "    mistral_summary = \"\"\n",
        "\n",
        "    for i in range(len(abstracts)):\n",
        "      prompt = f\"\"\"\n",
        "      Summarize this research paper: Title - {titles[i]}, abstract - {abstracts[i]}\n",
        "      Provide ONLY a well-structured summary that synthesizes the information from these papers with no additional text.\n",
        "      \"\"\"\n",
        "\n",
        "      gemini_summary += (query_gemini(prompt, gemini_api_key))\n",
        "      mistral_summary +=  (query_mistral(prompt, hf_api_token))\n",
        "      time.sleep(1)  # Add a small delay to avoid rate limiting\n",
        "\n",
        "    return {\n",
        "        \"gemini_ep\": gemini_summary,\n",
        "        \"mistral_ep\": mistral_summary\n",
        "    }\n",
        "\n",
        "def get_ensemble_summaries_for_each_paper(abstracts, titles, query, results_from_models=None):\n",
        "    \"\"\"\n",
        "    Create an ensemble of individual paper summaries from multiple models\n",
        "\n",
        "    Args:\n",
        "        abstracts (list): List of paper abstracts\n",
        "        titles (list): List of paper titles\n",
        "        query (str): The research question\n",
        "        results_from_models (dict, optional): Pre-computed model rankings\n",
        "\n",
        "    Returns:\n",
        "        str: The ensemble summary text combining individual paper summaries\n",
        "    \"\"\"\n",
        "    if not abstracts:\n",
        "        return \"No abstracts provided for summarization.\"\n",
        "\n",
        "    # Get API keys from environment variables\n",
        "    gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    hf_api_token = os.environ.get(\"MISTRAL_API_KEY\")\n",
        "\n",
        "    # Get individual paper summaries from both models\n",
        "    summaries = get_model_summaries_for_each_paper(abstracts, titles, query, gemini_api_key, hf_api_token)\n",
        "\n",
        "    # Create an ensemble summary if both model summaries exist\n",
        "    if summaries[\"gemini_ep\"] and summaries[\"mistral_ep\"]:\n",
        "        ensemble_prompt = f\"\"\"\n",
        "        I have two summaries of the same set of papers related to this research question: \"{query}\"\n",
        "\n",
        "        Summary 1:\n",
        "        {summaries[\"gemini_ep\"]}\n",
        "\n",
        "        Summary 2:\n",
        "        {summaries[\"mistral_ep\"]}\n",
        "\n",
        "        Please create a synthesis of these two summaries maintaining academic standard. Do not reference these summaries and just output the final summary.\n",
        "        \"\"\"\n",
        "\n",
        "        ensemble_summary = query_gemini(ensemble_prompt, gemini_api_key)\n",
        "        return ensemble_summary\n",
        "    elif summaries[\"gemini_ep\"]:\n",
        "        return summaries[\"gemini_ep\"]\n",
        "    elif summaries[\"mistral_ep\"]:\n",
        "        return summaries[\"mistral_ep\"]\n",
        "    else:\n",
        "        return \"Unable to generate summaries from the provided models.\"\n",
        "\n",
        "def evaluate_summaries_with_bert(summaries, reference_summary):\n",
        "    \"\"\"\n",
        "    Evaluate summaries using BERT score against a reference summary\n",
        "\n",
        "    Args:\n",
        "        summaries (dict): Dictionary of model names to summary texts\n",
        "        reference_summary (str): The reference summary to compare against\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of model names to score dictionaries (precision, recall, f1)\n",
        "    \"\"\"\n",
        "    scores = {}\n",
        "\n",
        "    # Evaluate each model's summary\n",
        "    for model_name, summary in summaries.items():\n",
        "        if summary:\n",
        "            try:\n",
        "                P, R, F1 = bert_score([summary], [reference_summary], lang=\"en\", rescale_with_baseline=True)\n",
        "                scores[model_name] = {\n",
        "                    \"precision\": P.item(),\n",
        "                    \"recall\": R.item(),\n",
        "                    \"f1\": F1.item()\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Error computing BERT Score for {model_name}: {e}\")\n",
        "                scores[model_name] = None\n",
        "\n",
        "    # If we have an ensemble summary, evaluate it too\n",
        "    if \"ensemble\" in summaries and summaries[\"ensemble\"]:\n",
        "        try:\n",
        "            P, R, F1 = bert_score([summaries[\"ensemble\"]], [reference_summary], lang=\"en\", rescale_with_baseline=True)\n",
        "            scores[\"ensemble\"] = {\n",
        "                \"precision\": P.item(),\n",
        "                \"recall\": R.item(),\n",
        "                \"f1\": F1.item()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error computing BERT Score for ensemble: {e}\")\n",
        "            scores[\"ensemble\"] = None\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "uJfGxxvodTpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract Screening\n",
        "\n",
        "The abstracts of the relevant papers go through screening process below. Screening strategy is used by ranking the papers with sentence transformers and ensemble model. All the ranks obtained by each paper will have a final consolidated ranking from the models to minimise the model bias using Reciprocal Rank Fusion\n",
        "\n",
        "### Sentence Transformers used\n",
        "The following pretrained sentence transformers are used:\n",
        "* BM25\n",
        "* SBERT\n",
        "* SPLADE\n",
        "\n",
        "and Ensemble model of Deepseek and Gemini LLMs.\n",
        "\n",
        "The abstracts are ranked on the relevance similarity scores based on mean consolidated embeddings with other abstracts and research question. Say, we have 'N' total papers retrieved and we use the above models(m ∈ [1,4]),\\\n",
        "<center>$R_{abs_i}^{model_m} = SS_{model_m}(abs_i, \\frac{1}{2N}(Σ_{j!=i}abs_j)+rq/2)$</center>, where,\\\n",
        "\n",
        "* R_{abs_i}^{model_m} is the rank of paper i with respect to model m,\n",
        "* SS_{model_m}(a, b) is similarity score with respect to model m between a and b, a and b are two text embedding vectors,\n",
        "* abs_i is abstract embedding vector of paper i,\n",
        "* rq is embedding vector of research question.\n",
        "\n",
        "Now, we have m ranks for each paper, which can possibly include model bias because they are trained over different kinds of data.\n",
        "\n",
        "To reduce this bias, we adopt RRF:\n",
        "<center> $Rank_{abs_i} = Σ_{j=1}^m \\frac{1}{k+R_{abs_i}^{model_j} }$</center>\n",
        "where,\n",
        "\n",
        "\n",
        "* Rank_{abs_i} is the final rank of i^{th} paper,\n",
        "* k is a constant, generally used 60\n",
        "* R_{abs_i}^{model_j} is the rank of i^{th} paper with respect to model j.\n",
        "\n"
      ],
      "metadata": {
        "id": "oe7pUW6WQqOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_abstracts_from_papers(results):\n",
        "    \"\"\"\n",
        "    Extract abstracts from the search results\n",
        "    \"\"\"\n",
        "    all_papers = results[\"EUROPEPMC\"] + results[\"DOAJ\"] + results[\"SEMANTIC\"]\n",
        "    abstracts = []\n",
        "    titles = []\n",
        "\n",
        "    for paper in all_papers:\n",
        "        title = paper.get(\"title\", \"\")\n",
        "        abstract = paper.get(\"abstract\", \"\")\n",
        "\n",
        "        if abstract is not None and abstract.strip():  # Only include papers with non-empty abstracts\n",
        "            abstracts.append(abstract)\n",
        "            titles.append(title)\n",
        "\n",
        "    return abstracts, titles"
      ],
      "metadata": {
        "id": "8po-6WpOl98C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "id": "g36geKZ-0vVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4e5496-c0fd-4e48-bafa-76de820a5748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Reciprocal Rank Fusion (RRF) Function\n",
        "def reciprocal_rank_fusion(ranked_lists, k=60):\n",
        "    scores = {}\n",
        "    for rank_list in ranked_lists:\n",
        "        for rank, doc_id in enumerate(rank_list):\n",
        "            scores[doc_id] = scores.get(doc_id, 0) + 1 / (k + rank + 1)\n",
        "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# BM25 Ranking\n",
        "def get_bm25_ranking(abstracts, query):\n",
        "    tokenized_abstracts = [doc.split() for doc in abstracts]\n",
        "    bm25 = BM25Okapi(tokenized_abstracts)\n",
        "    bm25_scores = bm25.get_scores(query.split())\n",
        "    return np.argsort(bm25_scores)[::-1], bm25_scores\n",
        "\n",
        "# SBERT Ranking\n",
        "def get_sbert_ranking(abstracts, query):\n",
        "    sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    abstract_embeddings = sbert_model.encode(abstracts, convert_to_tensor=True)\n",
        "    query_embedding = sbert_model.encode([query], convert_to_tensor=True)\n",
        "\n",
        "    # Calculate mean abstract embedding to use in similarity calculation\n",
        "    mean_abstract_embedding = torch.mean(abstract_embeddings, dim=0, keepdim=True)\n",
        "    # Combine mean abstract and research question as described in the formula\n",
        "    combined_embedding = 0.5 * mean_abstract_embedding + 0.5 * query_embedding\n",
        "\n",
        "    # Calculate similarity scores for each abstract with the combined embedding\n",
        "    abstract_embeddings = abstract_embeddings.cpu().numpy()\n",
        "    combined_embedding = combined_embedding.cpu().numpy()\n",
        "    sbert_scores = cosine_similarity(abstract_embeddings, combined_embedding).flatten()\n",
        "\n",
        "    return np.argsort(sbert_scores)[::-1], sbert_scores\n",
        "\n",
        "# SPLADE Ranking\n",
        "def get_splade_ranking(abstracts, query):\n",
        "    try:\n",
        "        splade_tokenizer = AutoTokenizer.from_pretrained(\"naver/splade-cocondenser-ensembledistil\")\n",
        "        splade_model = AutoModel.from_pretrained(\"naver/splade-cocondenser-ensembledistil\")\n",
        "\n",
        "        def get_splade_representation(text):\n",
        "            inputs = splade_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = splade_model(**inputs).last_hidden_state.mean(dim=1)\n",
        "            return outputs.squeeze().cpu().numpy()\n",
        "\n",
        "        splade_embeddings = np.array([get_splade_representation(text) for text in abstracts])\n",
        "        query_splade_embedding = get_splade_representation(query)\n",
        "\n",
        "        # Calculate mean abstract embedding\n",
        "        mean_splade_embedding = np.mean(splade_embeddings, axis=0)\n",
        "        # Combine mean abstract and research question\n",
        "        combined_embedding = 0.5 * mean_splade_embedding + 0.5 * query_splade_embedding\n",
        "\n",
        "        splade_scores = cosine_similarity(splade_embeddings, combined_embedding.reshape(1, -1)).flatten()\n",
        "        return np.argsort(splade_scores)[::-1], splade_scores\n",
        "    except Exception as e:\n",
        "        print(f\"Error in SPLADE ranking: {e}\")\n",
        "        # Return dummy ranking if SPLADE fails\n",
        "        return np.arange(len(abstracts)), np.zeros(len(abstracts))\n",
        "\n",
        "def printRankings(ranked_results):\n",
        "  for i in ranked_results:\n",
        "    print(f'Rank: {i[\"rank\"]}       Title:{i[\"title\"]}       Relevance Score:{i[\"relevance_score\"]}')\n",
        "    print(\"\\n\")\n",
        "\n",
        "def rank_abstracts(search_results, research_question, rfm=None):\n",
        "    # Extract abstracts from search results\n",
        "    abstracts, titles = get_abstracts_from_papers(search_results)\n",
        "\n",
        "    if not abstracts:\n",
        "        print(\"No abstracts found in the search results\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Ranking {len(abstracts)} abstracts based on relevance to research question...\")\n",
        "\n",
        "    # Get rankings from each model\n",
        "    bm25_ranked, bm25_scores = get_bm25_ranking(abstracts, research_question)\n",
        "    sbert_ranked, sbert_scores = get_sbert_ranking(abstracts, research_question)\n",
        "    splade_ranked, splade_scores = get_splade_ranking(abstracts, research_question)\n",
        "\n",
        "    # Collect results from the first three models to use in ensemble\n",
        "    results_from_models = {\n",
        "        \"bm25\": {\"ranking\": bm25_ranked.tolist(), \"scores\": bm25_scores.tolist()},\n",
        "        \"sbert\": {\"ranking\": sbert_ranked.tolist(), \"scores\": sbert_scores.tolist()},\n",
        "        \"splade\": {\"ranking\": splade_ranked.tolist(), \"scores\": splade_scores.tolist()}\n",
        "    }\n",
        "\n",
        "    # Get ensemble model ranking\n",
        "    ensemble_ranked, ensemble_scores = get_ensemble_ranking(abstracts, titles, research_question, rfm)\n",
        "\n",
        "    # Apply RRF to Combine Rankings\n",
        "    ranked_lists = [bm25_ranked, sbert_ranked, splade_ranked, ensemble_ranked]\n",
        "    final_ranking = reciprocal_rank_fusion(ranked_lists)\n",
        "\n",
        "    # Create the final ranked results\n",
        "    ranked_results = []\n",
        "    for idx, (doc_id, score) in enumerate(final_ranking):\n",
        "        if doc_id < len(titles):  # Ensure valid index\n",
        "            ranked_results.append({\n",
        "                \"rank\": idx + 1,\n",
        "                \"title\": titles[doc_id],\n",
        "                \"abstract\": abstracts[doc_id],\n",
        "                \"relevance_score\": score\n",
        "            })\n",
        "\n",
        "    # Save rankings for later use\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    with open(\"results/abstract_rankings.json\", \"w\") as f:\n",
        "        json.dump(ranked_results, f, indent=2)\n",
        "\n",
        "    return ranked_results"
      ],
      "metadata": {
        "id": "kiO3DObMWgz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ranking the abstracts"
      ],
      "metadata": {
        "id": "W48dAFc8DzCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------CODE TO RUN THE PIPELINE----------------------#\n",
        "def run_review_pipeline(query, abstracts, titles, reference_summary=None):\n",
        "\n",
        "    gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    hf_api_token = os.environ.get(\"MISTRAL_API_KEY\")\n",
        "\n",
        "    print(\"Getting model rankings...\")\n",
        "    model_rankings = get_model_rankings(abstracts, titles, query, gemini_api_key, hf_api_token)\n",
        "\n",
        "    print(\"Creating ensemble ranking...\")\n",
        "    ensemble_ranked, ensemble_scores = get_ensemble_ranking(abstracts, titles, query, model_rankings)\n",
        "\n",
        "    print(\"Final ranking...\")\n",
        "    final_ranking = rank_abstracts(search_results, query, model_rankings)\n",
        "\n",
        "    print(\"Generating model summaries...\")\n",
        "    model_summaries = get_model_summaries(abstracts, titles, ensemble_ranked, query, gemini_api_key, hf_api_token)\n",
        "\n",
        "    print(\"Creating ensemble summary...\")\n",
        "    ensemble_summary = get_ensemble_summaries(abstracts, titles, query, model_rankings)\n",
        "\n",
        "    print(\"Generating model summaries for each paper...\")\n",
        "    model_summaries_ep = get_model_summaries_for_each_paper(abstracts, titles, query, gemini_api_key, hf_api_token)\n",
        "\n",
        "    print(\"Creating ensemble summary for each paper..\")\n",
        "    ensemble_summary_ep = get_ensemble_summaries_for_each_paper(abstracts, titles, query, model_rankings)\n",
        "\n",
        "    all_summaries = {\n",
        "        \"gemini\": model_summaries[\"gemini\"],\n",
        "        \"mistral\": model_summaries[\"mistral\"],\n",
        "        \"ensemble\": ensemble_summary,\n",
        "        \"gemini_ep\": model_summaries_ep[\"gemini_ep\"],\n",
        "        \"mistral_ep\": model_summaries_ep[\"mistral_ep\"],\n",
        "        \"ensemble_ep\": ensemble_summary_ep\n",
        "    }\n",
        "\n",
        "    results = {\n",
        "        \"rankings\": {\n",
        "            \"gemini\": model_rankings[\"gemini\"],\n",
        "            \"mistral\": model_rankings[\"mistral\"],\n",
        "            \"ensemble\": {\n",
        "                \"ranking\": ensemble_ranked.tolist(),\n",
        "                \"scores\": ensemble_scores.tolist()\n",
        "            },\n",
        "            \"final\" : final_ranking\n",
        "        },\n",
        "        \"summaries\": all_summaries\n",
        "    }\n",
        "\n",
        "    # Step 5: Evaluate with BERT Score if reference is provided\n",
        "    if reference_summary:\n",
        "        print(\"Evaluating summaries with BERT Score...\")\n",
        "        bert_scores = evaluate_summaries_with_bert(all_summaries, reference_summary)\n",
        "        results[\"evaluation\"] = bert_scores\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ayTLrQUYlPGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstracts, titles = get_abstracts_from_papers(search_results)\n",
        "results = run_review_pipeline(query, abstracts, titles)\n",
        "\n",
        "# Print rankings\n",
        "print(\"\\nPaper Rankings:\")\n",
        "print(\"==============\")\n",
        "print(\"\\nGemini Ranking:\")\n",
        "# print(\"results!!!----------->\", results)\n",
        "for i, idx in enumerate(results[\"rankings\"][\"gemini\"][\"ranking\"]):\n",
        "    print(f\"{i+1}. {titles[idx-1]}\")\n",
        "\n",
        "print(\"\\nMistral Ranking:\")\n",
        "for i, idx in enumerate(results[\"rankings\"][\"mistral\"][\"ranking\"]):\n",
        "    print(f\"{i+1}. {titles[idx-1]}\")\n",
        "\n",
        "print(\"\\nEnsemble Ranking:\")\n",
        "for i, idx in enumerate(results[\"rankings\"][\"ensemble\"][\"ranking\"]):\n",
        "    print(f\"{i+1}. {titles[idx]} (Score: {results['rankings']['ensemble']['scores'][i]:.4f})\")\n",
        "\n",
        "print(\"\\nFinal Ranking:\")\n",
        "for i in (results[\"rankings\"][\"final\"]):\n",
        "  print(f\"{i['rank']}.{i['title']} (Score: {i['relevance_score']:.4f})\")\n",
        "\n",
        "# Print summaries (truncated for brevity)\n",
        "print(\"\\nConsolidated Summary:\")\n",
        "print(\"=================================\")\n",
        "for model, summary in results[\"summaries\"].items():\n",
        "    if summary:\n",
        "        print(f\"\\n{model.capitalize()} Summary: {summary[:]}...\")\n",
        "\n",
        "# Print BERT Score evaluation\n",
        "if \"evaluation\" in results:\n",
        "    print(\"\\nBERT Score Evaluation:\")\n",
        "    print(\"=====================\")\n",
        "    for model, scores in results[\"evaluation\"].items():\n",
        "        if scores:\n",
        "            print(f\"\\n{model.capitalize()}:\")\n",
        "            print(f\"  Precision: {scores['precision']:.4f}\")\n",
        "            print(f\"  Recall: {scores['recall']:.4f}\")\n",
        "            print(f\"  F1: {scores['f1']:.4f}\")\n"
      ],
      "metadata": {
        "id": "5qGgP4xmlf5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0a32c7-477b-48d8-b580-16008da0c0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting model rankings...\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Creating ensemble ranking...\n",
            "Final ranking...\n",
            "Ranking 22 abstracts based on relevance to research question...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at naver/splade-cocondenser-ensembledistil and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating model summaries...\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Creating ensemble summary...\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Generating model summaries for each paper...\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Creating ensemble summary for each paper..\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "Sending prompt to Mistral API...\n",
            "Warning: Response is not valid JSON. Returning raw text.\n",
            "\n",
            "Paper Rankings:\n",
            "==============\n",
            "\n",
            "Gemini Ranking:\n",
            "1. Artificial Intelligence-Assisted Chest X-ray for the Diagnosis of COVID-19: A Systematic Review and Meta-Analysis\n",
            "2. HTLML: Hybrid AI Based Model for Detection of Alzheimer’s Disease\n",
            "3. Augmenting Radiological Diagnostics with AI for Tuberculosis and COVID-19 Disease Detection: Deep Learning Detection of Chest Radiographs\n",
            "4. Advances in Ultrasound-Guided Surgery and Artificial Intelligence Applications in Musculoskeletal Diseases\n",
            "5. Impact of Image Resolution on Deep Learning Performance in Endoscopy Image Classification: An Experimental Study Using a Large Dataset of Endoscopic Images\n",
            "6. Embracing AI: The Imperative Tool for Echo Labs to Stay Ahead of the Curve\n",
            "7. Recent Advances in the Field of Artificial Intelligence for Precision Medicine in Patients with a Diagnosis of Metastatic Cutaneous Melanoma\n",
            "8. Combining External Medical Knowledge for Improving Obstetric Intelligent Diagnosis: Model Development and Validation\n",
            "9. Improve the efficiency and accuracy of ophthalmologists’ clinical decision-making based on AI technology\n",
            "10. Artificial intelligence and machine learning in precision and genomic medicine\n",
            "11. Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\n",
            "12. Combined Artificial Intelligence Approaches Analyzing 1000 Conservative Patients with Back Pain—A Methodological Pathway to Predicting Treatment Efficacy and Diagnostic Groups\n",
            "13. Prevent Medical Errors through Artificial Intelligence: A Review\n",
            "14. Artificial intelligence and machine learning in haematology\n",
            "15. Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives\n",
            "16. Methodology for testing and monitoring AI-based software for medical diagnostics\n",
            "17. Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study\n",
            "18. Features of Mobile Apps for People with Autism in a Post COVID-19 Scenario: Current Status and Recommendations for Apps Using AI\n",
            "19. Forecasting Patient Early Readmission from Irish Hospital Discharge Records Using Conventional Machine Learning Models\n",
            "20. Generative AI in Undergraduate Medical Education: A Rapid Review\n",
            "21. Evolution of research and development in the field of artificial intelligence technologies for healthcare in the Russian Federation: results of 2021\n",
            "22. Cancer: A Computational Disease that AI Can Cure\n",
            "\n",
            "Mistral Ranking:\n",
            "1. HTLML: Hybrid AI Based Model for Detection of Alzheimer’s Disease\n",
            "2. Embracing AI: The Imperative Tool for Echo Labs to Stay Ahead of the Curve\n",
            "3. Recent Advances in the Field of Artificial Intelligence for Precision Medicine in Patients with a Diagnosis of Metastatic Cutaneous Melanoma\n",
            "4. Augmenting Radiological Diagnostics with AI for Tuberculosis and COVID-19 Disease Detection: Deep Learning Detection of Chest Radiographs\n",
            "5. Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study\n",
            "6. Advances in Ultrasound-Guided Surgery and Artificial Intelligence Applications in Musculoskeletal Diseases\n",
            "7. Impact of Image Resolution on Deep Learning Performance in Endoscopy Image Classification: An Experimental Study Using a Large Dataset of Endoscopic Images\n",
            "8. Artificial Intelligence-Assisted Chest X-ray for the Diagnosis of COVID-19: A Systematic Review and Meta-Analysis\n",
            "9. Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives\n",
            "10. Evolution of research and development in the field of artificial intelligence technologies for healthcare in the Russian Federation: results of 2021\n",
            "11. Combining External Medical Knowledge for Improving Obstetric Intelligent Diagnosis: Model Development and Validation\n",
            "12. Cancer: A Computational Disease that AI Can Cure\n",
            "13. Combined Artificial Intelligence Approaches Analyzing 1000 Conservative Patients with Back Pain—A Methodological Pathway to Predicting Treatment Efficacy and Diagnostic Groups\n",
            "14. Artificial intelligence and machine learning in haematology\n",
            "15. Improve the efficiency and accuracy of ophthalmologists’ clinical decision-making based on AI technology\n",
            "16. Methodology for testing and monitoring AI-based software for medical diagnostics\n",
            "17. Generative AI in Undergraduate Medical Education: A Rapid Review\n",
            "18. Artificial intelligence and machine learning in precision and genomic medicine\n",
            "19. Prevent Medical Errors through Artificial Intelligence: A Review\n",
            "20. Features of Mobile Apps for People with Autism in a Post COVID-19 Scenario: Current Status and Recommendations for Apps Using AI\n",
            "21. Forecasting Patient Early Readmission from Irish Hospital Discharge Records Using Conventional Machine Learning Models\n",
            "22. Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\n",
            "\n",
            "Ensemble Ranking:\n",
            "1. Embracing AI: The Imperative Tool for Echo Labs to Stay Ahead of the Curve (Score: 0.0435)\n",
            "2. Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study (Score: 0.0833)\n",
            "3. Features of Mobile Apps for People with Autism in a Post COVID-19 Scenario: Current Status and Recommendations for Apps Using AI (Score: 0.6667)\n",
            "4. Recent Advances in the Field of Artificial Intelligence for Precision Medicine in Patients with a Diagnosis of Metastatic Cutaneous Melanoma (Score: 0.2500)\n",
            "5. Forecasting Patient Early Readmission from Irish Hospital Discharge Records Using Conventional Machine Learning Models (Score: 0.0526)\n",
            "6. Impact of Image Resolution on Deep Learning Performance in Endoscopy Image Classification: An Experimental Study Using a Large Dataset of Endoscopic Images (Score: 0.0625)\n",
            "7. Artificial Intelligence-Assisted Chest X-ray for the Diagnosis of COVID-19: A Systematic Review and Meta-Analysis (Score: 0.0714)\n",
            "8. Cancer: A Computational Disease that AI Can Cure (Score: 0.2000)\n",
            "9. Improve the efficiency and accuracy of ophthalmologists’ clinical decision-making based on AI technology (Score: 0.1667)\n",
            "10. Generative AI in Undergraduate Medical Education: A Rapid Review (Score: 0.2222)\n",
            "11. HTLML: Hybrid AI Based Model for Detection of Alzheimer’s Disease (Score: 0.2000)\n",
            "12. Artificial intelligence and machine learning in haematology (Score: 0.0500)\n",
            "13. Methodology for testing and monitoring AI-based software for medical diagnostics (Score: 0.0645)\n",
            "14. Advances in Ultrasound-Guided Surgery and Artificial Intelligence Applications in Musculoskeletal Diseases (Score: 0.1053)\n",
            "15. Combining External Medical Knowledge for Improving Obstetric Intelligent Diagnosis: Model Development and Validation (Score: 0.0588)\n",
            "16. Augmenting Radiological Diagnostics with AI for Tuberculosis and COVID-19 Disease Detection: Deep Learning Detection of Chest Radiographs (Score: 0.0800)\n",
            "17. Artificial intelligence and machine learning in precision and genomic medicine (Score: 0.0714)\n",
            "18. Combined Artificial Intelligence Approaches Analyzing 1000 Conservative Patients with Back Pain—A Methodological Pathway to Predicting Treatment Efficacy and Diagnostic Groups (Score: 0.0625)\n",
            "19. Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms (Score: 0.2857)\n",
            "20. Prevent Medical Errors through Artificial Intelligence: A Review (Score: 0.0909)\n",
            "21. Evolution of research and development in the field of artificial intelligence technologies for healthcare in the Russian Federation: results of 2021 (Score: 0.0833)\n",
            "22. Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives (Score: 0.0541)\n",
            "\n",
            "Final Ranking:\n",
            "1.Embracing AI: The Imperative Tool for Echo Labs to Stay Ahead of the Curve (Score: 0.0641)\n",
            "2.Recent Advances in the Field of Artificial Intelligence for Precision Medicine in Patients with a Diagnosis of Metastatic Cutaneous Melanoma (Score: 0.0616)\n",
            "3.Cancer: A Computational Disease that AI Can Cure (Score: 0.0594)\n",
            "4.Prevent Medical Errors through Artificial Intelligence: A Review (Score: 0.0587)\n",
            "5.Artificial intelligence and machine learning in haematology (Score: 0.0587)\n",
            "6.Evolution of research and development in the field of artificial intelligence technologies for healthcare in the Russian Federation: results of 2021 (Score: 0.0586)\n",
            "7.Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study (Score: 0.0579)\n",
            "8.Methodology for testing and monitoring AI-based software for medical diagnostics (Score: 0.0575)\n",
            "9.Artificial intelligence and machine learning in precision and genomic medicine (Score: 0.0570)\n",
            "10.Combined Artificial Intelligence Approaches Analyzing 1000 Conservative Patients with Back Pain—A Methodological Pathway to Predicting Treatment Efficacy and Diagnostic Groups (Score: 0.0568)\n",
            "11.Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives (Score: 0.0562)\n",
            "12.Artificial Intelligence-Assisted Chest X-ray for the Diagnosis of COVID-19: A Systematic Review and Meta-Analysis (Score: 0.0561)\n",
            "13.Combining External Medical Knowledge for Improving Obstetric Intelligent Diagnosis: Model Development and Validation (Score: 0.0560)\n",
            "14.Generative AI in Undergraduate Medical Education: A Rapid Review (Score: 0.0552)\n",
            "15.Forecasting Patient Early Readmission from Irish Hospital Discharge Records Using Conventional Machine Learning Models (Score: 0.0552)\n",
            "16.Features of Mobile Apps for People with Autism in a Post COVID-19 Scenario: Current Status and Recommendations for Apps Using AI (Score: 0.0539)\n",
            "17.Impact of Image Resolution on Deep Learning Performance in Endoscopy Image Classification: An Experimental Study Using a Large Dataset of Endoscopic Images (Score: 0.0535)\n",
            "18.Advances in Ultrasound-Guided Surgery and Artificial Intelligence Applications in Musculoskeletal Diseases (Score: 0.0532)\n",
            "19.Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms (Score: 0.0530)\n",
            "20.HTLML: Hybrid AI Based Model for Detection of Alzheimer’s Disease (Score: 0.0528)\n",
            "21.Improve the efficiency and accuracy of ophthalmologists’ clinical decision-making based on AI technology (Score: 0.0527)\n",
            "22.Augmenting Radiological Diagnostics with AI for Tuberculosis and COVID-19 Disease Detection: Deep Learning Detection of Chest Radiographs (Score: 0.0526)\n",
            "\n",
            "Consolidated Summary:\n",
            "=================================\n",
            "\n",
            "Gemini Summary: **Summary of AI in Medical Diagnostics**\n",
            "\n",
            "**1. Key Themes and Findings:**\n",
            "\n",
            "*   **AI's Broad Applicability:** AI transforms medical imaging (echocardiography, melanoma), assists individuals with ASD, and improves hospital readmission prediction.\n",
            "*   **Diagnostic Enhancement:** AI enhances image quality, automates measurements, and improves diagnostic accuracy (echocardiography, melanoma).\n",
            "*   **Personalized and Precision Medicine:** AI facilitates personalized content delivery, automated reasoning, and image recognition for precision medicine (melanoma, ASD).\n",
            "*   **Improved Efficiency and Outcomes:** AI adoption optimizes workflows, reduces workload burden, and improves patient outcomes (echocardiography, hospital readmission).\n",
            "*   **ML Adoption Challenges:** Clinics face challenges in adopting ML systems due to ML-specific factors (adoption process).\n",
            "*   **Predictive capabilities**: Machine learning models can leverage routinely collected hospital data to forecast patient readmission.\n",
            "\n",
            "**2. Methodological Approaches:**\n",
            "\n",
            "*   **Literature Reviews:** Overviews of AI's impact on echocardiography and precision medicine for melanoma.\n",
            "*   **Qualitative Interviews:** Exploration of factors influencing ML system adoption in clinics (semi-structured interviews, content analysis).\n",
            "*   **Mobile App Analysis:** Identification of AI-driven features in mobile apps for individuals with ASD (PRISMA methodology, app deconstruction).\n",
            "*   **Machine Learning Model Development:** Forecasting patient readmission using various ML models (SHAP value visualization for interpretation).\n",
            "\n",
            "**3. Gaps in the Literature:**\n",
            "\n",
            "*   **Standardization:** Need for standardized protocols for AI implementation in echocardiography.\n",
            "*   **ML Adoption Barriers:** Challenges in ML adoption in clinical settings.\n",
            "*   **Generalizability:** Translating AI solutions from bench to bedside in melanoma.\n",
            "*   **Model Transparency:** Need for interpretable AI models.\n",
            "\n",
            "**4. Directions for Future Research:**\n",
            "\n",
            "*   **Collaboration:** Foster collaboration between experts, AI researchers, and industry for AI innovation in echocardiography.\n",
            "*   **ML Adoption Frameworks:** Develop and apply ML adoption frameworks and maturity models for clinical settings.\n",
            "*   **AI-Driven Feature Enhancement:** Explore further AI enhancements for ASD apps, like progress tracking and personalized content delivery.\n",
            "*   **Clinical Translation of AI:** Standardize the implementation of AI techniques for routine adoption in clinical settings for melanoma.\n",
            "*   **Explainable AI:** Focus on explainable AI techniques to explore the correlation between data features and patient outcomes, specifically in predicting readmission rates.\n",
            "...\n",
            "\n",
            "Mistral Summary: ### Comprehensive Summary\n",
            "\n",
            "#### Key Themes and Findings\n",
            "1. **AI in Medical Diagnostics**: AI technologies, including machine learning (ML) and deep learning, are transforming medical diagnostics by enhancing image quality, automating measurements, and improving diagnostic accuracy.\n",
            "2. **Specialized Applications**: AI is being applied in various medical fields, such as echocardiography, autism support, metastatic cutaneous melanoma management, and patient readmission prediction.\n",
            "3. **Enhanced Patient Care**: AI-driven tools can improve patient outcomes by providing personalized treatment plans, tracking progress, and predicting future health risks.\n",
            "4. **Challenges and Adoption**: Despite the potential benefits, the adoption of AI in clinical settings faces challenges, including the need for standardized protocols, training of medical professionals, and addressing data imbalance issues.\n",
            "\n",
            "#### Methodological Approaches\n",
            "1. **Qualitative and Quantitative Studies**: The papers employ a mix of qualitative (interviews, content analysis) and quantitative (model benchmarking, feature engineering) methods.\n",
            "2. **Content Analysis**: Used to identify factors influencing AI adoption in clinics, leading to the development of a maturity model for ML systems.\n",
            "3. **Machine Learning Models**: Various ML models, including conventional and deep learning techniques, are evaluated for their effectiveness in medical diagnostics and patient readmission prediction.\n",
            "4. **Explainable AI**: Techniques like SHapley Additive Explanations (SHAP) are used to interpret model predictions and identify key predictors of health outcomes.\n",
            "\n",
            "#### Gaps in the Literature\n",
            "1. **Standardization**: There is a need for standardized protocols for AI implementation in medical diagnostics to ensure reproducibility and generalizability.\n",
            "2. **Training and Collaboration**: More emphasis is required on training medical professionals in AI technologies and fostering collaboration between medical experts, AI researchers, and industry stakeholders.\n",
            "3. **Data Imbalance**: Addressing data imbalance and the variety of data types is crucial for improving the performance of ML algorithms in medical diagnostics.\n",
            "4. **Specific Applications**: While AI has shown promise in various medical fields, there is a need for more research on its application in specific medical conditions and patient populations.\n",
            "\n",
            "#### Directions for Future Research\n",
            "1. **Standardized Protocols**: Develop and implement standardized protocols for AI integration in medical diagnostics to ensure consistent and reliable outcomes.\n",
            "2. **Training Programs**: Create comprehensive training programs for medical professionals to enhance their understanding and application of AI technologies.\n",
            "3. **Interdisciplinary Collaboration**: Encourage collaboration between medical experts, AI researchers, and industry stakeholders to drive innovation and address challenges in AI adoption.\n",
            "4. **Explainable AI**: Further research is needed to develop and apply explainable AI techniques to improve the interpretability of AI-driven diagnostic tools.\n",
            "5. **Personalized Medicine**: Explore the potential of AI in personalized medicine, focusing on individualized treatment plans and progress tracking for various medical conditions.\n",
            "6. **Ethical Considerations**: Investigate the ethical implications of AI in medical diagnostics, including data privacy, bias, and equity in healthcare delivery....\n",
            "\n",
            "Ensemble Summary: ### Synthesis: AI in Medical Diagnostics\n",
            "\n",
            "**Key Themes and Findings:**\n",
            "\n",
            "AI demonstrates significant potential to enhance medical diagnostics across various fields, including echocardiography, general medical diagnostics, precision medicine, and ASD support. AI algorithms improve image quality, automate measurements, and enhance disease diagnosis, leading to potentially better patient outcomes. However, successful AI integration necessitates addressing adoption challenges and ensuring diagnostic accuracy. Machine Learning (ML) systems, including deep learning, can predict patient readmission using hospital discharge records, identifying key predictors like cancer and COPD. AI's ability to mine medical images has shown promise in improving the management of conditions like metastatic cutaneous melanoma.\n",
            "\n",
            "**Methodological Approaches:**\n",
            "\n",
            "Research employs a mix of qualitative and quantitative methodologies. Qualitative studies, such as interviews with medical experts, explore factors influencing AI adoption. Quantitative studies involve benchmarking machine learning models, applying feature engineering techniques (e.g., SHAP) to improve model performance and interpretability. Systematic reviews and meta-analyses following PRISMA guidelines ensure rigorous and transparent reporting. Maturity models are used to assess the state of AI adoption in medical settings.\n",
            "\n",
            "**Gaps in the Literature:**\n",
            "\n",
            "Standardization and protocols for AI implementation in medical diagnostics are lacking, hindering routine clinical adoption. Clinics face significant challenges in adopting ML systems, highlighting the need for guiding frameworks. Further research is needed to understand AI application for specific conditions like ASD and metastatic cutaneous melanoma. Explainability of AI models, particularly in areas like readmission prediction, needs improvement. Addressing data imbalance and incorporating wider data ranges is needed to improve predictive modeling performance.\n",
            "\n",
            "**Directions for Future Research:**\n",
            "\n",
            "Future research should prioritize collaboration between medical professionals, AI researchers, and industry stakeholders to drive innovation and establish standardized protocols. The development and evaluation of AI features in ASD support apps, focusing on progress tracking, personalized content delivery, and automated reasoning, is essential. Continued research into predictive modeling for patient readmission, incorporating diverse data types and addressing data imbalance issues, is warranted. Exploration of AI's potential in precision medicine for conditions like metastatic cutaneous melanoma should be pursued to enhance treatment planning, monitoring, and outcomes. Development and validation of frameworks and maturity models to guide AI system adoption in clinics are needed to ensure clinicians can fully benefit from AI's diagnostic potential. Prospective validation of AI diagnostic tools in real-world clinical settings should also be prioritised.\n",
            "...\n",
            "\n",
            "Gemini_ep Summary: This study investigates consumer perceptions of AI-based medical devices with clinical decision support (CDS) features in healthcare. Using an online survey of 307 US individuals, the research examines perceived benefits and risks. The study found that technological, ethical (trust), and regulatory concerns significantly contribute to the perceived risks, with technological concerns being the most significant predictor of risk beliefs. The research proposes recommendations to reduce these concerns, suggesting normative standards, evaluation guidelines, regular audits, and ongoing monitoring to ensure safety, quality, transparency, and ethical practices. The findings offer implications for research and practice in AI-based CDS implementation.\n",
            "The research paper \"HTLML: Hybrid AI Based Model for Detection of Alzheimer’s Disease\" proposes a hybrid AI model to improve the early detection of Alzheimer's Disease (AD) using medical images. The model combines transfer learning (TL) with a permutation-based machine learning (ML) voting classifier.\n",
            "\n",
            "**Phase 1:** Feature extraction using two TL models: DenseNet-121 and DenseNet-201.\n",
            "\n",
            "**Phase 2:** Classification using three ML classifiers: SVM, Naïve Bayes, and XGBoost, with final results determined by a voting mechanism.\n",
            "\n",
            "The model was trained and tested using a Kaggle dataset of 6200 MRI images categorized into four dementia levels. The proposed model achieved an accuracy of 91.75%, specificity of 96.5%, and an F1-score of 90.25%, outperforming existing state-of-the-art models. The authors suggest this model's performance indicates potential for therapeutically viable AD detection methods from MRI images.\n",
            "AI is rapidly transforming echocardiography, offering potential to enhance image quality, automate measurements, and improve cardiovascular disease diagnosis. Echo labs must embrace AI to overcome workload burden, improve diagnostic accuracy, and optimize patient outcomes. Training professionals in AI implementation is crucial. Collaboration between experts, researchers, and industry is necessary to drive innovation and standardize AI protocols in echocardiography. AI adoption is imperative for echo labs to maintain leadership and deliver state-of-the-art cardiac care.\n",
            "This research paper investigates mobile applications for individuals with Autism Spectrum Disorder (ASD) in the post-COVID-19 landscape, focusing on apps utilizing Artificial Intelligence (AI). The study identified 46 relevant apps from an initial pool of 250, filtering based on criteria related to ASD users and their interactions with medical staff and caregivers. Detailed analysis of 25 downloaded apps revealed key features, including eye tracking, facial expression analysis, 3D cartoons, haptic feedback, engaging interfaces, text-to-speech, Applied Behavior Analysis (ABA) therapy, and Augmentative and Alternative Communication (AAC) techniques. The study proposes enhancements for ASD apps using AI in areas like progress tracking, personalized content delivery, automated reasoning, image recognition, and Natural Language Processing (NLP). The research followed the PRISMA methodology to ensure systematic review and meta-analysis reporting.\n",
            "**Problem:** Medical errors are a major threat to patient safety and healthcare quality globally.\n",
            "\n",
            "**Objective:** Review the types, causes, and potential solutions for medical errors.\n",
            "\n",
            "**Approach:** Narrative review of existing literature.\n",
            "\n",
            "**Solutions Emphasized:**\n",
            "*   Multidisciplinary approach.\n",
            "*   Improved communication.\n",
            "*   Enhanced education and training.\n",
            "*   Implementation of technology, especially artificial intelligence (AI).\n",
            "*   Quality improvement initiatives.\n",
            "*   Ongoing monitoring and reporting of errors.\n",
            "\n",
            "**Key Finding/Potential:** AI holds transformative potential for healthcare, offering opportunities to improve diagnostics, treatment planning, patient monitoring, and healthcare management, thereby reducing medical errors.\n",
            "AI and machine learning are advancing precision medicine by enabling early disease risk prediction, improved diagnostics, and customized treatments. By analyzing comprehensive patient data, AI can identify biological indicators of health changes. Genomic medicine, combined with AI, addresses unique patient healthcare needs and uncommon therapeutic responses. AI's advanced computation and inference enhance physician decision-making. High-throughput measurements of cell characteristics serve as training objectives for predictive models. Increased availability of datasets and modern ML techniques are fostering a new era of effective genomic medicine. This review article highlights ML algorithms' contributions to precision and genome medicine.\n",
            "Ultrasound imaging is increasingly used in minimally invasive musculoskeletal surgery, but it suffers from operator dependency and image quality limitations. Artificial intelligence (AI) and deep learning (DL) offer solutions by improving screening for conditions like hip dysplasia and osteochondritis dissecans, enhancing diagnostic accuracy for carpal tunnel syndrome, and providing better prognostic tools for knee osteoarthritis. DL methods, including segmentation, detection, and localization, can also improve the accuracy and efficiency of ultrasound-guided procedures. This review summarizes the advances in ultrasound-guided procedures for musculoskeletal diseases and comprehensively overviews the application of AI/DL in musculoskeletal ultrasound, particularly in surgery.\n",
            "This research paper investigates the impact of image resolution on the performance of deep learning models for endoscopic image classification. Using the HyperKvasir dataset of 10,662 endoscopic images across 23 findings, the study evaluates two CNN models across resolutions ranging from 32x32 to 512x512 pixels. Performance was measured using F1-score, MCC, precision, and sensitivity via two-fold cross-validation. The key finding is that higher image resolution leads to improved classification performance, with the highest MCC (0.9002) achieved at 512x512 resolution. The study concludes that image resolution significantly influences CNN performance in endoscopy, advocating for the establishment of resolution standards in the field.\n",
            "This meta-analysis investigates the diagnostic accuracy of AI-assisted chest X-rays for COVID-19 detection. Researchers analyzed nine studies comprising 39,603 subjects, finding a pooled sensitivity of 0.9472 and a specificity of 0.9610. The area under the SROC was 0.98, indicating excellent diagnostic potential. The heterogeneity was low. The study concludes that AI-assisted chest X-rays offer a promising tool for COVID-19 diagnosis.\n",
            "AI techniques like radiomics, machine learning, and deep learning can enhance precision medicine for metastatic cutaneous melanoma by improving the analysis of medical images (CT, MRI, PET). These techniques extract data from images (tumor volume, heterogeneity, shape) to provide insights into cancer biology for improved patient care. AI can improve detection/diagnosis, staging, treatment planning/delivery, response assessment, toxicity assessment, and monitoring. Standardization of AI implementation can translate these advancements into routine clinical use, improving outcome prediction accuracy and generalizability for patients globally.\n",
            "**Objective:** Predict patient readmission from Irish hospital discharge records to improve healthcare risk management.\n",
            "\n",
            "**Methods:**\n",
            "*   Compared conventional machine learning and deep learning models on a multimodal dataset.\n",
            "*   Used patient demographics, hospitalization history, and clinical diagnoses.\n",
            "*   Addressed data imbalance and varied data types.\n",
            "*   Employed SHAP values to interpret predictions and identify key features.\n",
            "\n",
            "**Results:**\n",
            "*   Improved AUROC score from 0.628 to 0.7 through feature engineering.\n",
            "*   Identified cancer, COPD, and social factors as significant predictors of 30-day readmission.\n",
            "*   Bacterial carrier status showed minimal impact.\n",
            "\n",
            "**Conclusion:**\n",
            "*   Conventional machine learning can effectively forecast readmission using hospital data.\n",
            "*   Explainable AI techniques reveal correlations between data features and readmission rates.\n",
            "*   **Focus:** Examines the development of AI technologies for healthcare in Russia in 2021.\n",
            "*   **Context:** AI in healthcare is a priority within Russia's national AI development strategy, aiming to improve healthcare quality and patient outcomes.\n",
            "*   **Progress:** Domestic market for AI healthcare solutions has emerged, some products are registered as medical devices, and research is ongoing.\n",
            "*   **Challenges:** Russia lags behind leading countries like the US and China in AI development for healthcare; Investments decreased significantly in 2021.\n",
            "*   **Barriers:** Low demand, funding limitations in state medical organizations, and lack of trust in the safety and effectiveness of AI solutions are key challenges.\n",
            "The research paper \"Combining External Medical Knowledge for Improving Obstetric Intelligent Diagnosis: Model Development and Validation\" addresses the challenge of leveraging electronic medical records (EMRs) and external medical knowledge for improved obstetric diagnosis. The study introduces a novel neural network model, the knowledge-aware hierarchical diagnosis model (KHDM), to address the multilabel classification task inherent in diagnosing diverse conditions from EMRs. KHDM integrates Chinese obstetric EMRs and external knowledge documents using an attention mechanism within a hierarchical deep learning framework. The model was evaluated on a real-world dataset and achieved an accuracy of 0.8929, outperforming existing methods, and demonstrating improved interpretability. The research concludes that KHDM effectively incorporates domain knowledge to significantly enhance diagnostic accuracy.\n",
            "*   **Problem:** Cancer is a leading cause of death, posing a complex, high-dimensional search problem for effective treatments due to diverse subtypes, many target options, and limited high-quality data.\n",
            "\n",
            "*   **Opportunity:** Growing availability of molecular diagnostics and electronic medical records.\n",
            "\n",
            "*   **Approach:** Applying AI techniques to personalize and improve cancer treatment, as exemplified by Cancer Commons, a \"rapid learning\" community.\n",
            "\n",
            "*   **Research Areas:** Adaptive treatment planning, causal mechanism inference, individual drug response prediction, and generalization to new cases.\n",
            "\n",
            "*   **Goal:** Individualized treatment based on the best available knowledge, continually updated to benefit future patients.\n",
            "This research paper explores the use of combined artificial intelligence (AI) approaches to predict treatment efficacy and underlying diagnostic groups in 1000 conservatively treated back pain patients. The study investigates the potential of supervised and unsupervised AI methods, developing a methodology to combine their predictions. Supervised AI showed promise in predicting therapy efficiency near the minimal clinical difference threshold. Unsupervised AI revealed patterns within the data. The study demonstrates that combining different AI approaches alongside baseline data is necessary to identify underlying diagnostic groups. The presented methodology offers a transferable approach for establishing correlations in heterogeneous datasets where individual AI methods yield limited results.\n",
            "Artificial intelligence (AI) and machine learning (ML) are poised to revolutionize healthcare, particularly in haematology.\n",
            "\n",
            "Potential Applications:\n",
            "\n",
            "*   **Decision Support:** AI/ML-driven software can guide referring clinicians through algorithms, suggesting next steps for investigation of common haematological queries and escalating urgent cases to specialists.\n",
            "*   **Automated Blood Film Reporting:** Digitizing blood films, coupled with AI/ML pattern recognition and clinical data integration, can automate routine reporting, flagging complex cases for human review.\n",
            "*   **Prediction and Risk Stratification:** ML models can integrate patient data to predict disease progression (e.g., in MGUS or CML) and treatment complications, optimizing patient management.\n",
            "\n",
            "Despite the potential, research applying AI/ML in haematology remains limited.\n",
            "**Summary:**\n",
            "\n",
            "*   **Background:** Investment in AI-based medical diagnostic software is growing, but standardized testing and monitoring protocols are lacking.\n",
            "*   **Aim:** To develop a universal methodology for testing and monitoring AI-based software for medical diagnostics.\n",
            "*   **Methods:** Literature review and practical approbation via an experiment in Moscow's healthcare system.\n",
            "*   **Results:** A 7-stage methodology was developed: self-testing, functional testing, calibration testing, technological monitoring, clinical monitoring, feedback, and refinement.\n",
            "*   **Conclusion:** The cyclical methodology, detailed requirements, and physician involvement facilitate continuous improvement, enabling developers to demonstrate quality and users to make informed choices.\n",
            "This research paper explores the use of deep learning to detect pneumonia, COVID-19, and tuberculosis from chest X-ray images. The study compares the performance of VGG16 and ResNet50 neural networks, finding that ResNet50 outperforms VGG16 in accuracy and resilience. Data augmentation techniques were used to enhance the images for training. ResNet50 achieved high precision and recall rates (near 0.99) for all conditions in the test set, demonstrating its effectiveness in classifying lung ailments. The study concludes that this deep learning approach, particularly with ResNet50, has the potential to improve clinical diagnostics and transform care strategies for diseases like COVID-19 and tuberculosis.\n",
            "This qualitative study investigates the adoption of machine learning (ML) systems for medical diagnostics in clinics. Through interviews with 22 medical experts, it identifies 13 ML-specific factors influencing adoption, categorized into 7 domains forming an ML adoption framework. The research also develops a maturity model to assess a clinic's progress in ML adoption. The findings highlight that clinics face challenges in adopting ML, preventing them from realizing its potential. The framework and maturity model serve as a guide for future research and a practical reference for clinicians.\n",
            "**Objective:** Develop an AI-powered platform to improve the diagnostic efficiency and accuracy of ophthalmologists, particularly junior doctors, in diagnosing ocular fundus diseases.\n",
            "\n",
            "**Methods:**\n",
            "*   Leveraged electronic medical records (EMRs) data.\n",
            "*   Employed Named Entity Recognition (NER) using the SoftLexicon-Glove-Word2vec model to extract key information from EMRs.\n",
            "*   Generated feature variables based on diagnostic rule templates.\n",
            "*   Utilized XGBoost algorithm to build an intelligent decision support platform.\n",
            "*   Evaluated platform effectiveness through a controlled experiment comparing experienced and junior doctors.\n",
            "\n",
            "**Results:**\n",
            "*   Significant improvements in diagnostic efficiency and accuracy for both experienced and junior doctors (P < 0.05) with the platform.\n",
            "*   The gap in diagnostic speed and precision between junior and experienced doctors narrowed when using the platform.\n",
            "*   Junior doctors experienced more pronounced benefits than experienced doctors.\n",
            "\n",
            "**Conclusion:**\n",
            "*   The platform, based on XGBoost and NER, effectively enhances the diagnostic capabilities of junior doctors in ocular fundus diseases.\n",
            "**Purpose:** To investigate current and potential uses of generative AI in undergraduate medical education (UME).\n",
            "\n",
            "**Methodology:** A rapid review of literature published before June 30, 2023, was conducted across six databases using a librarian-generated search strategy. Inclusion criteria focused on osteopathic/allopathic UME and defined generative AI implementation strategies. Two reviewers screened articles, extracted data, and confirmed findings.\n",
            "\n",
            "**Results:** Out of 521 articles, 41 underwent full-text review. Most were opinion pieces, case reports, or editorials. Seven articles used qualitative or quantitative methods. Generative AI uses in UME were categorized as: nonclinical learning assistant, content developer, virtual patient interaction, clinical decision-making tutor, and medical writing. Potential was greatest for virtual patient and clinical decision-making tutor roles.\n",
            "\n",
            "**Conclusion:** While generative AI holds promise in UME, quantitative evidence supporting improved learner outcomes is limited. Research should focus on the effectiveness of incorporating generative AI into preclinical and clinical curricula.\n",
            "**Summary:**\n",
            "\n",
            "*   **Premise:** Clinician-machine collaboration can improve medical decision-making by addressing current fragilities.\n",
            "*   **Challenge:** Realization requires precise disease definitions, dynamics, and interactions, necessitating probabilistic analysis of symptoms, signs, and molecular profiles.\n",
            "*   **Analogy:** Statistical physics, used to extract macroscopic states from microscopic elements in physical systems, offers relevant approaches.\n",
            "*   **Approach:** Application of statistical physics, machine learning, and inference algorithms to medical diagnostics.\n",
            "*   **Goal:** Improve current medical diagnostic approaches.\n",
            "...\n",
            "\n",
            "Mistral_ep Summary: **Summary:**\n",
            "\n",
            "- **Background**: AI is increasingly integrated into healthcare, improving prognosis, diagnostics, and care planning. Patients are key beneficiaries, and their perceptions influence AI adoption. While AI can enhance healthcare, potential risks and concerns must be addressed.\n",
            "\n",
            "- **Objective**: To examine consumers' perceived benefits and risks of AI medical devices with clinical decision support (CDS) features.\n",
            "\n",
            "- **Methodology**: An online survey was conducted with 307 individuals in the United States, focusing on value perceptions specific to healthcare.\n",
            "\n",
            "- **Results**:\n",
            "  - Technological, ethical, and regulatory concerns significantly contribute to perceived risks.\n",
            "  - Technological concerns (performance and communication features) are the most significant predictors of risk beliefs.\n",
            "  - The study identifies sources of motivation and pressure for patients in the development of AI-based devices.\n",
            "\n",
            "- **Conclusions**:\n",
            "  - The study highlights factors affecting perceived risks and offers recommendations to mitigate these concerns.\n",
            "  - Regulatory agencies and healthcare institutions should collaborate to establish standards and guidelines for AI implementation.\n",
            "  - Continuous evaluation of AI-based services is recommended to ensure safety, quality, transparency, and ethical considerations.**Summary:**\n",
            "\n",
            "- **Objective:** Develop a hybrid AI model for early detection of Alzheimer’s Disease (AD) using MRI images.\n",
            "- **Problem:** Traditional imaging methods (CT, MRI, PET) are time-consuming and labor-intensive for early AD diagnosis.\n",
            "- **Proposed Solution:** A hybrid AI model combining transfer learning (TL) and permutation-based machine learning (ML) voting classifier.\n",
            "- **Model Architecture:**\n",
            "  - **Phase 1:** Feature extraction using DenseNet-121 and DenseNet-201.\n",
            "  - **Phase 2:** Classification using SVM, Naïve Bayes, and XGBoost with a voting mechanism.\n",
            "- **Dataset:** 6200 MRI images from Kaggle, categorized as mildly demented (896), moderately demented (64), non-demented (3200), and extremely mildly demented (1966).\n",
            "- **Performance Metrics:**\n",
            "  - Accuracy: 91.75%\n",
            "  - Specificity: 96.5%\n",
            "  - F1-score: 90.25%\n",
            "- **Conclusion:** The proposed model outperforms existing state-of-the-art models and shows potential for clinical application in AD detection.**Summary:**\n",
            "\n",
            "The research paper \"Embracing AI: The Imperative Tool for Echo Labs to Stay Ahead of the Curve\" discusses the transformative potential of artificial intelligence (AI) in the field of echocardiography. Key points include:\n",
            "\n",
            "- **AI's Impact on Echocardiography:** AI-driven technologies can significantly enhance diagnostic capabilities in echo labs by improving image quality, automating measurements, and accurately diagnosing cardiovascular diseases.\n",
            "\n",
            "- **Importance of AI Adoption:** Embracing AI is crucial for echo labs to stay competitive and improve patient care. It helps address challenges such as high workloads and variability in diagnostic accuracy, thereby enhancing efficiency and patient outcomes.\n",
            "\n",
            "- **Training and Integration:** The paper emphasizes the need for training echo lab professionals in AI implementation to ensure seamless integration into routine clinical practice.\n",
            "\n",
            "- **Collaboration and Standardization:** Collaboration between echocardiography experts, AI researchers, and industry stakeholders is essential to drive innovation and establish standardized protocols for AI implementation in echocardiography.\n",
            "\n",
            "- **Conclusion:** The paper concludes that adopting AI in echocardiography labs is not optional but imperative for maintaining leadership and delivering advanced cardiac care in the era of modern medical technologies.**Summary:**\n",
            "\n",
            "- **Context**: The COVID-19 pandemic has necessitated a reassessment of how people with Autism Spectrum Disorder (ASD) can thrive, leading to an increased focus on telehealth services.\n",
            "\n",
            "- **Objective**: The study aims to identify mobile applications suitable for individuals with ASD, particularly those utilizing Artificial Intelligence (AI) technologies.\n",
            "\n",
            "- **Methodology**:\n",
            "  - 250 mobile apps were retrieved using keywords related to autism and AI.\n",
            "  - 46 apps were identified as relevant after filtering out irrelevant ones.\n",
            "  - 25 apps were downloaded and analyzed for common functionalities and features.\n",
            "\n",
            "- **Analyzed Features**:\n",
            "  - Eye tracking\n",
            "  - Facial expression analysis\n",
            "  - Use of 3D cartoons\n",
            "  - Haptic feedback\n",
            "  - Engaging interface\n",
            "  - Text-to-speech\n",
            "  - Applied Behaviour Analysis therapy\n",
            "  - Augmentative and Alternative Communication techniques\n",
            "\n",
            "- **Recommendations for Future Development**:\n",
            "  - Progress tracking\n",
            "  - Personalized content delivery\n",
            "  - Automated reasoning\n",
            "  - Image recognition\n",
            "  - Natural Language Processing (NLP)\n",
            "\n",
            "- **Methodological Approach**: The study follows the PRISMA methodology for systematic reviews and meta-analyses.**Summary:**\n",
            "\n",
            "- **Problem**: Medical errors are a global concern, threatening patient safety and care quality.\n",
            "- **Review Scope**: This narrative review examines medical errors, their types, causes, and potential solutions based on current literature.\n",
            "- **Solutions**:\n",
            "  - Multidisciplinary approach including:\n",
            "    - Improved communication\n",
            "    - Enhanced education and training\n",
            "    - Technology and artificial intelligence (AI) implementation\n",
            "    - Quality improvement initiatives\n",
            "  - Ongoing monitoring and reporting of medical errors\n",
            "- **AI in Healthcare**: AI is highlighted as a transformative technology with potential to revolutionize healthcare by:\n",
            "  - Improving diagnostics\n",
            "  - Enhancing treatment planning\n",
            "  - Aiding patient monitoring\n",
            "  - Streamlining healthcare management**Summary:**\n",
            "\n",
            "- **Precision Medicine Advancements**: Precision medicine has shifted from conventional symptom-driven treatments to early disease risk prediction and personalized treatments through improved diagnostics.\n",
            "\n",
            "- **Role of AI and Machine Learning**: AI and machine learning (ML) enhance precision and genomic medicine by providing advanced computation and inference, aiding physician decision-making, and enabling the system to reason and learn.\n",
            "\n",
            "- **Data Utilization**: Comprehensive patient data and broad factors are analyzed to differentiate between healthy and ill individuals, improving the understanding of biological indicators of health changes.\n",
            "\n",
            "- **Genomic Medicine Technologies**: These technologies are particularly beneficial for patients with unique healthcare needs or uncommon therapeutic responses.\n",
            "\n",
            "- **High-Throughput Measurements**: Characteristics such as gene up-regulation, protein-nucleic acid binding, and splicing are measured at high throughput and used to train predictive models.\n",
            "\n",
            "- **Data and Techniques**: The availability of diverse datasets and modern computational techniques, including ML, are driving a new era of effective genomic medicine.\n",
            "\n",
            "- **Contributions of ML Algorithms**: The review highlights the significant contributions of ML algorithms in advancing precision and genomic medicine.**Summary:**\n",
            "\n",
            "- **Ultrasound in Musculoskeletal Medicine:**\n",
            "  - Ultrasound imaging is crucial in musculoskeletal medicine, particularly in minimally invasive procedures for sports, foot and ankle, and hand surgery.\n",
            "  - Recent years have seen an increase in publications on ultrasound-guided surgery.\n",
            "\n",
            "- **Challenges with Ultrasound Imaging:**\n",
            "  - Operator dependency and image obscurity are notable drawbacks.\n",
            "\n",
            "- **Role of Artificial Intelligence (AI) and Deep Learning (DL):**\n",
            "  - AI and DL can mitigate the limitations of ultrasound imaging.\n",
            "  - AI/DL applications include:\n",
            "    - Enhancing screening for hip dysplasia and osteochondritis dissecans (OCD) of the humeral capitellum.\n",
            "    - Improving diagnostic accuracy for carpal tunnel syndrome (CTS).\n",
            "    - Providing better prognostic tools for knee osteoarthritis.\n",
            "\n",
            "- **DL Methods in Ultrasound-Guided Procedures:**\n",
            "  - DL methods, such as segmentation, detection, and localization of target tissues and medical instruments, can enhance the accuracy and efficiency of ultrasound-guided procedures.\n",
            "\n",
            "- **Review Focus:**\n",
            "  - The review summarizes recent advances in ultrasound-guided procedures for musculoskeletal diseases.\n",
            "  - It provides an overview of AI/DL utilization in ultrasound for musculoskeletal medicine, with a focus on ultrasound-guided surgery.**Summary:**\n",
            "\n",
            "- **Research Focus:** Impact of image resolution on deep learning performance in endoscopy image classification.\n",
            "- **Dataset:** HyperKvasir, comprising 10,662 images across 23 different findings.\n",
            "- **Models Evaluated:** Two CNN architectures for endoscopic image classification.\n",
            "- **Resolution Range:** 32 × 32 to 512 × 512 pixels.\n",
            "- **Evaluation Metrics:** F1-score, Matthews correlation coefficient (MCC), precision, and sensitivity.\n",
            "- **Key Findings:**\n",
            "  - Higher image resolutions generally improved performance.\n",
            "  - Optimal performance (MCC of 0.9002) was achieved at 512 × 512 pixels.\n",
            "  - Image resolution significantly influences CNN performance, suggesting a need for standardized image resolutions in GI endoscopy.\n",
            "- **Methodology:** Two-fold cross-validation was used to assess model performance.**Summary:**\n",
            "\n",
            "- **Objective:** To evaluate the clinical value of AI-assisted chest X-rays for diagnosing COVID-19.\n",
            "- **Methodology:**\n",
            "  - Systematic review and meta-analysis of studies published between January 1, 2020, and May 30, 2022.\n",
            "  - Databases searched: PubMed, Cochrane Library, MedRxiv, ArXiv, and Embase.\n",
            "  - Inclusion criteria: Studies using AI for COVID-19 diagnosis with relevant parameters (sensitivity, specificity, area under curve).\n",
            "  - Nine studies with 39,603 subjects were included.\n",
            "- **Findings:**\n",
            "  - Pooled sensitivity: 0.9472 (95% CI 0.9009–0.9959, p = 0.0338).\n",
            "  - Pooled specificity: 0.9610 (95% CI 0.9428–0.9795, p < 0.0001).\n",
            "  - Area under the summary receiver operating characteristic (SROC) curve: 0.98 (95% CI 0.94–1.00).\n",
            "  - Heterogeneity of diagnostic odds ratio: I² = 36.212, p = 0.129.\n",
            "- **Conclusion:** AI-assisted chest X-rays show excellent diagnostic potential for detecting COVID-19 and have broad application prospects.**Summary:**\n",
            "\n",
            "The research paper discusses the integration of artificial intelligence (AI) techniques in the management of metastatic cutaneous melanoma, focusing on the enhancement of medical imaging for precision medicine. Key points include:\n",
            "\n",
            "- **Current Imaging Techniques**: Standard medical imaging methods like CT, MRI, and PET are essential in managing metastatic cutaneous melanoma.\n",
            "- **AI Techniques**: AI, including radiomics, machine learning, and deep learning, can extract detailed information from medical images, such as tumor volume, heterogeneity, and shape.\n",
            "- **Applications of AI**: AI can improve various aspects of patient care, including detection/diagnosis, staging, treatment planning, delivery, response assessment, toxicity assessment, and monitoring.\n",
            "- **Clinical Translation**: The paper explores the potential for translating AI-driven insights into clinical practice, emphasizing the need for standardization to ensure accuracy, reproducibility, and generalizability.\n",
            "- **Future Prospects**: The goal is to implement AI techniques in routine clinical settings worldwide to enhance patient outcomes in metastatic cutaneous melanoma.**Summary:**\n",
            "\n",
            "- **Objective:** The study aims to predict patient readmission within 30 days using electronic discharge records from an Irish hospital, focusing on improving healthcare risk management and patient outcomes.\n",
            "\n",
            "- **Methods:**\n",
            "  - **Data:** Multimodal dataset including patient demographics, historical hospitalization records, and clinical diagnosis codes.\n",
            "  - **Models:** Comparison of conventional machine learning models and deep learning models.\n",
            "  - **Challenges Addressed:** Data imbalance and variety of data types.\n",
            "  - **Explainability:** Use of SHapley Additive Explanations (SHAP) values to interpret model predictions and identify key features and diagnosis codes associated with readmission risks.\n",
            "\n",
            "- **Results:**\n",
            "  - Improved area under the curve (AUROC) score from 0.628 to 0.7 on the test dataset through feature engineering techniques.\n",
            "  - Identified significant predictors of 30-day readmission risk, including diagnoses such as cancer, COPD, and certain social factors.\n",
            "  - Found that bacterial carrier status had minimal impact due to lower case frequencies.\n",
            "\n",
            "- **Conclusions:** The study successfully utilized routinely collected hospital data to forecast patient readmission using conventional machine learning models and explainable AI techniques, revealing correlations between data features and patient readmission rates.**Summary:**\n",
            "\n",
            "- **Priority Area**: AI technologies in healthcare are a key focus of Russia's national AI development strategy.\n",
            "- **Applications**: AI is being integrated into various healthcare domains, including preventive care, diagnostics, disease prediction, drug dosage optimization, pandemic threat reduction, and surgical automation.\n",
            "- **Regulation and Market**: Policy management and technical regulations for AI in healthcare are in development. A domestic market for AI healthcare solutions exists, with some products certified as medical devices.\n",
            "- **Research Activity**: Multiple scientific teams are conducting research in this field.\n",
            "- **Global Standing**: Russia lags behind leading countries like the U.S. and China in AI healthcare.\n",
            "- **Investment and Funding**: Investments in AI healthcare products decreased significantly in 2021 due to low demand and insufficient state funding.\n",
            "- **Trust Issues**: There are concerns regarding the safety and effectiveness of AI healthcare solutions.**Summary:**\n",
            "\n",
            "- **Background:** Data-driven medical health information processing is increasingly important in obstetrics, with electronic medical records (EMRs) serving as a crucial information source for intelligent diagnosis.\n",
            "- **Objective:** To enhance the performance of intelligent diagnosis in EMRs by incorporating external medical knowledge.\n",
            "- **Methods:**\n",
            "  - Treated intelligent diagnosis as a multilabel classification task due to the multiple diagnostic results in EMRs.\n",
            "  - Developed a neural network knowledge-aware hierarchical diagnosis model (KHDM) that integrates Chinese obstetric EMRs and external medical knowledge.\n",
            "  - Utilized an attention mechanism within a hierarchical deep learning framework to combine EMRs and external knowledge, enriching the language model with curated knowledge documents.\n",
            "- **Results:**\n",
            "  - Evaluated KHDM on a real-world Chinese obstetric EMR dataset.\n",
            "  - Achieved an accuracy of 0.8929, surpassing advanced classification benchmark methods.\n",
            "  - Demonstrated the model’s interpretability advantage.\n",
            "- **Conclusions:** KHDM effectively integrates domain knowledge, significantly improving the accuracy of diagnosis in Chinese EMRs.**Summary:**\n",
            "\n",
            "- **Problem**: Cancer is a leading cause of death, and treating it effectively is a complex, high-dimensional search problem due to the variety of cancer subtypes, potential targets, drug combinations, and limited high-quality data.\n",
            "\n",
            "- **Opportunities and Challenges**: The increasing availability of molecular diagnostics and electronic medical records offers opportunities for AI to personalize and enhance cancer treatment, but also presents challenges in data integration and analysis.\n",
            "\n",
            "- **Cancer Commons Initiative**: A \"rapid learning\" community where patients, physicians, and researchers collaborate to collect and analyze molecular and clinical data from cancer patients to individualize therapies.\n",
            "\n",
            "- **Research Opportunities**:\n",
            "  - Adaptively planning and executing treatment experiments across patient populations.\n",
            "  - Inferring causal mechanisms of tumors.\n",
            "  - Predicting drug responses in individuals.\n",
            "  - Generalizing findings to new cases.\n",
            "\n",
            "- **Goal**: To treat each patient based on the best available knowledge and continually update this knowledge to benefit future patients.\n",
            "\n",
            "- **AI Grand Challenge**: Utilizing AI to address the complexities of cancer treatment and improve patient outcomes.**Summary:**\n",
            "\n",
            "- **Objective:** To predict treatment efficacy and diagnostic groups in 1000 conservative back pain patients using combined artificial intelligence (AI) approaches.\n",
            "- **Challenge:** Back pain has multiple causes and varied treatment responses, making it difficult to manage in clinical practice.\n",
            "- **Methods:**\n",
            "  - Applied both supervised and unsupervised AI methods.\n",
            "  - Developed a methodology to combine predictions from different AI approaches.\n",
            "- **Findings:**\n",
            "  - Supervised AI effectively predicted therapy efficiency at the minimal clinical difference threshold.\n",
            "  - Unsupervised AI identified patterns within the dataset.\n",
            "  - Combining different AI approaches and baseline data was crucial for identifying underlying diagnostic groups.\n",
            "- **Conclusion:** The combined AI methodology provides a transferable pathway to establish correlations in heterogeneous datasets, especially when individual AI methods yield weak results.### Summary of \"Artificial Intelligence and Machine Learning in Haematology\"\n",
            "\n",
            "**Overview:**\n",
            "- **Artificial Intelligence (AI)** and **Machine Learning (ML)** are emerging technologies with significant potential in healthcare, particularly in haematology.\n",
            "- AI encompasses machines performing complex tasks such as decision-making, problem-solving, and language understanding.\n",
            "- ML, a subset of AI, uses statistical techniques to enable systems to learn from data.\n",
            "\n",
            "**Healthcare Applications:**\n",
            "- The 2018 Chief Medical Officer’s report highlights the potential of AI and ML in healthcare, emphasizing the use of big data and computing power for prediction and diagnostics.\n",
            "- Examples include the 100,000 Genomes Project and the UK Biobank, which provide large datasets for AI and ML applications.\n",
            "\n",
            "**Potential in Haematology:**\n",
            "1. **Decision Support for Referrals:**\n",
            "   - AI-driven software can guide clinicians through algorithms to manage high-volume, low-complexity queries.\n",
            "   - The system can suggest next steps for investigation and notify haematology teams for complex or urgent cases.\n",
            "   - Secure messaging applications can facilitate communication, replacing outdated methods like pagers or WhatsApp.\n",
            "\n",
            "2. **Automated Blood Film Reporting:**\n",
            "   - Digitization of blood films is already possible, creating a vast library of normal and abnormal samples.\n",
            "   - Intelligent systems can cross-check clinical records and use pattern recognition to decide if human intervention is needed.\n",
            "   - Automated reports can be sent via email or app, with urgent cases flagged for immediate attention.\n",
            "\n",
            "3. **Prediction and Risk Stratification:**\n",
            "   - Large datasets can aid in predicting laboratory parameter developments and patient outcomes.\n",
            "   - This can optimize outpatient clinic time and anticipate complications, improving patient care.\n",
            "   - Examples include predicting paraprotein levels in MGUS or white blood counts in CML.\n",
            "\n",
            "**Current Research:**\n",
            "- Despite the potential, only a few studies have been published on AI and ML in haematology.\n",
            "- A systematic literature search revealed 12 original papers in the last five years, indicating a nascent but growing field.**Summary:**\n",
            "\n",
            "- **Background:**\n",
            "  - Significant investment growth in AI-based medical diagnostic software (2016: $80M, 2017: $152M).\n",
            "  - Lack of uniform standards and protocols for testing and monitoring AI-based software in medical diagnostics.\n",
            "\n",
            "- **Aim:**\n",
            "  - Develop a universal methodology for testing and monitoring AI-based software for medical diagnostics to improve quality and facilitate practical healthcare implementation.\n",
            "\n",
            "- **Materials and Methods:**\n",
            "  - Literature review on PubMed and eLIBRARY databases.\n",
            "  - Practical application of the methodology in an experiment using computer vision for medical image analysis in Moscow's healthcare system.\n",
            "\n",
            "- **Results:**\n",
            "  - Developed a 7-stage methodology:\n",
            "    1. Self-testing\n",
            "    2. Functional testing\n",
            "    3. Calibration testing\n",
            "    4. Technological monitoring\n",
            "    5. Clinical monitoring\n",
            "    6. Feedback\n",
            "    7. Refinement\n",
            "\n",
            "- **Conclusion:**\n",
            "  - Methodology features cyclical stages for continuous quality improvement.\n",
            "  - Includes detailed software performance requirements and physician involvement in evaluation.\n",
            "  - Benefits both developers and users by ensuring high-quality, independently verified software.This research paper presents a deep learning approach for identifying pneumonia, COVID-19, and tuberculosis using chest X-ray images. The study focuses on distinguishing between tuberculosis, COVID-19, and healthy lung conditions. It employs advanced neural networks, specifically VGG16 and ResNet50, to enhance the detection of lung issues from X-ray images. Data augmentation techniques were used to prepare the images for model training. The performance of the models was evaluated using precision, recall, and F1 scores across training, validation, and testing datasets.\n",
            "\n",
            "The ResNet50 model demonstrated superior performance compared to VGG16, achieving higher accuracy and resilience. It exhibited superior ROC AUC values in both validation and test scenarios, with precision and recall rates nearing 0.99 for all conditions in the test set. VGG16 also performed well, particularly in detecting tuberculosis with a precision of 0.99 and a recall of 0.93. The study concludes that ResNet50 outperforms traditional approaches like VGG16, showcasing the effectiveness of deep learning in improving classification accuracy through data augmentation and balancing. This advancement has the potential to transform clinical diagnostics by enhancing the accuracy and reliability of diagnosing diseases such as COVID-19 and tuberculosis.**Summary:**\n",
            "\n",
            "**Objective:**\n",
            "The study investigates factors influencing the adoption of machine learning (ML) systems for medical diagnostics in clinics and develops a maturity model to assess clinics' progress in adopting these systems.\n",
            "\n",
            "**Methods:**\n",
            "A qualitative approach involving semi-structured interviews with 22 medical experts from clinics and suppliers was used. Interviews were transcribed and analyzed using content analysis based on the health care–specific framework of nonadoption, abandonment, scale-up, spread, and sustainability.\n",
            "\n",
            "**Results:**\n",
            "13 ML-specific factors affecting adoption were identified and categorized into 7 domains, forming a holistic ML adoption framework for clinics. A maturity model was created to help practitioners evaluate their current state in the ML adoption process.\n",
            "\n",
            "**Key Findings:**\n",
            "- **Factors Influencing Adoption:** The study highlighted 13 factors that impact the adoption of ML systems in clinics.\n",
            "- **Domains of Influence:** These factors were grouped into 7 domains, providing a comprehensive view of the adoption process.\n",
            "- **Maturity Model:** The developed maturity model offers a practical tool for clinics to assess their readiness and progress in adopting ML systems.\n",
            "\n",
            "**Conclusion:**\n",
            "Despite the potential benefits of ML systems in medical diagnostics, many clinics face challenges in their adoption. The ML adoption framework and maturity model can guide future research and serve as practical tools for clinicians to navigate the adoption process.**Summary:**\n",
            "\n",
            "- **Background:** The increasing prevalence of ocular fundus diseases due to global aging and the strained doctor-patient ratio in China necessitate improved diagnostic capabilities, particularly among junior ophthalmologists.\n",
            "- **Objective:** To develop an AI-based diagnostic intelligent decision support platform using electronic medical record (EMR) data to enhance the diagnostic efficiency and accuracy of junior doctors.\n",
            "- **Methods:**\n",
            "  - Compared eight Chinese Named Entity Recognition (NER) models, selecting the SoftLexicon-Glove-Word2vec model (F1 score: 93.02%) for extracting key information from EMRs.\n",
            "  - Utilized the XGBoost algorithm to create the diagnostic support platform.\n",
            "  - Conducted a controlled experiment to evaluate the platform's effectiveness with both junior and experienced doctors.\n",
            "- **Results:**\n",
            "  - The platform significantly improved diagnostic efficiency and accuracy for both junior and experienced doctors.\n",
            "  - The performance gap between junior and experienced doctors narrowed when using the platform.\n",
            "  - Experienced doctors also benefited from the platform, but the improvement was more pronounced for junior doctors.\n",
            "- **Conclusion:** The AI-based diagnostic platform effectively enhances the diagnostic capabilities of junior ophthalmologists, contributing to better clinical outcomes for ocular fundus diseases.**Summary:**\n",
            "\n",
            "- **Objective**: To explore the current and potential uses of generative AI in undergraduate medical education (UME).\n",
            "\n",
            "- **Method**: Rapid review of literature published before June 30, 2023, across six databases, focusing on osteopathic and allopathic UME and defined uses of generative AI.\n",
            "\n",
            "- **Findings**:\n",
            "  - 521 articles screened, 41 underwent full-text review.\n",
            "  - Majority were opinion pieces, case reports, letters, editorials, and commentaries (32).\n",
            "  - 7 articles used qualitative and/or quantitative methods.\n",
            "  - Five categories of generative AI use in UME identified:\n",
            "    1. Nonclinical learning assistant\n",
            "    2. Content developer\n",
            "    3. Virtual patient interaction\n",
            "    4. Clinical decision-making tutor\n",
            "    5. Medical writing\n",
            "  - Greatest potential seen in virtual patient interaction and clinical decision-making tutor roles.\n",
            "  - Limited quantitative evidence of generative AI's impact on learner outcomes.\n",
            "\n",
            "- **Conclusion**: While generative AI shows promise in UME, more research is needed to evaluate its effectiveness in preclinical and clinical curricula.The research paper \"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\" explores the potential of integrating statistical physics with medical diagnostics to enhance decision-making in healthcare. The paper posits that collaboration between clinicians and machines can mitigate the decisional weaknesses in current medical practices. To achieve this, it is essential to define disease states and their dynamics more precisely, which involves a probabilistic analysis of symptoms, signs, and molecular profiles of relevant biochemical networks. This approach aims to create an unbiased and efficient diagnostic method.\n",
            "\n",
            "The paper draws parallels between medical diagnostics and problems studied in statistical physics, where macroscopic states of physical systems are derived from microscopic elements and their interactions. By leveraging these principles, the paper discusses how recent advancements in statistical physics, machine learning, and inference algorithms can be applied to improve medical diagnostic techniques....\n",
            "\n",
            "Ensemble_ep Summary: ## Synthesis of Research on AI in Medical Diagnostics\n",
            "\n",
            "Artificial intelligence (AI) is rapidly transforming medical diagnostics across various specialties, offering the potential to enhance accuracy, efficiency, and personalization of patient care. This synthesis examines key trends and findings from recent research exploring the application of AI in diagnostic settings, covering areas from image analysis and disease detection to decision support and risk prediction.\n",
            "\n",
            "One prominent area of AI application is medical imaging. Deep learning models, particularly convolutional neural networks (CNNs), are being leveraged to improve the analysis of endoscopic images, chest X-rays, musculoskeletal ultrasounds, and MRI scans for the detection of conditions such as pneumonia, COVID-19, tuberculosis, Alzheimer's disease, and metastatic cutaneous melanoma. Studies demonstrate that image resolution significantly impacts CNN performance, highlighting the need for standardized image characteristics. AI-assisted chest X-rays, for instance, show excellent diagnostic potential for COVID-19 detection, while AI/DL methods in musculoskeletal ultrasound enhance screening for hip dysplasia and improve carpal tunnel syndrome diagnosis. Furthermore, AI-driven image analysis can extract tumor characteristics to improve detection, diagnosis, staging, and treatment planning for metastatic melanoma.\n",
            "\n",
            "Beyond image analysis, AI is being implemented to improve diagnostic accuracy and decision-making in other medical fields. In obstetrics, knowledge-aware hierarchical diagnosis models (KHDMs) are being developed to integrate electronic medical records (EMRs) and external medical knowledge, leading to significant improvements in diagnostic accuracy. For ocular fundus diseases, AI-based decision support platforms leverage EMR data to enhance diagnostic efficiency and accuracy, particularly for junior ophthalmologists. AI is also being explored for predicting patient readmission using hospital discharge records, identifying key predictors such as cancer and COPD, and for predicting therapy efficacy in conservatively treated back pain patients by combining supervised and unsupervised AI methods.\n",
            "\n",
            "Despite the potential benefits, the adoption of AI in medical diagnostics faces several challenges. Ethical, regulatory, and technological concerns significantly contribute to perceived risks among consumers, underscoring the need for establishing normative standards, evaluation guidelines, and monitoring systems to ensure safe, ethical, and transparent implementation. Furthermore, standardized testing and monitoring protocols for AI-based diagnostic software are lacking, necessitating the development of universal methodologies for quality improvement. Factors influencing the adoption of machine learning (ML) systems in clinics also require consideration, with studies identifying key domains and developing maturity models to guide practitioners through the adoption process. In undergraduate medical education, generative AI offers possibilities as a nonclinical learning assistant, content developer, and virtual patient interaction tool, yet quantitative evidence of its effectiveness in improving learner outcomes is still needed.\n",
            "\n",
            "Overall, AI holds significant promise for revolutionizing medical diagnostics, but successful implementation requires addressing technological limitations, ethical considerations, and regulatory gaps. Further research is needed to evaluate the effectiveness of AI-driven diagnostic tools, establish standardized protocols, and promote collaboration between clinicians, researchers, and industry to ensure the safe, effective, and equitable use of AI in healthcare.\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference_summary = \"\"\"\n",
        "# Background\n",
        "# Disasters are becoming more frequent due to the impact of extreme weather events attributed to climate change, causing loss of lives, property, and psychological trauma. Mental health response to disasters emphasizes prevention and mitigation, and mobile health (mHealth) apps have been used for mental health promotion and treatment. However, little is known about their use in the mental health components of disaster management.\n",
        "\n",
        "# Objective\n",
        "# This scoping review was conducted to explore the use of mobile phone apps for mental health responses to natural disasters and to identify gaps in the literature.\n",
        "\n",
        "# Methods\n",
        "# We identified relevant keywords and subject headings and conducted comprehensive searches in 6 electronic databases. Studies in which participants were exposed to a man-made disaster were included if the sample also included some participants exposed to a natural hazard. Only full-text studies published in English were included. The initial titles and abstracts of the unique papers were screened by 2 independent review authors. Full texts of the selected papers that met the inclusion criteria were reviewed by the 2 independent reviewers. Data were extracted from each selected full-text paper and synthesized using a narrative approach based on the outcome measures, duration, frequency of use of the mobile phone apps, and the outcomes. This scoping review was reported according to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews).\n",
        "\n",
        "# Results\n",
        "# Of the 1398 papers retrieved, 5 were included in this review. A total of 3 studies were conducted on participants exposed to psychological stress following a disaster while 2 were for disaster relief workers. The mobile phone apps for the interventions included Training for Life Skills, Sonoma Rises, Headspace, Psychological First Aid, and Substance Abuse and Mental Health Services Administration (SAMHSA) Behavioural Health Disaster Response Apps. The different studies assessed the effectiveness or efficacy of the mobile app, feasibility, acceptability, and characteristics of app use or predictors of use. Different measures were used to assess the effectiveness of the apps’ use as either the primary or secondary outcome.\n",
        "\n",
        "# Conclusions\n",
        "# A limited number of studies are exploring the use of mobile phone apps for mental health responses to disasters. The 5 studies included in this review showed promising results. Mobile apps have the potential to provide effective mental health support before, during, and after disasters. However, further research is needed to explore the potential of mobile phone apps in mental health responses to all hazards.\n",
        "\n",
        "# Keywords: mental health, disasters, mobile health, mHealth, application, applications, app, apps, smartphone, stress, psychological, traumatic, disaster, disasters, hazard, hazards, emergency, psychological trauma, mobile apps, trauma, scoping, review methods, review methodology, mobile phone\n",
        "# \"\"\"\n",
        "# abstracts, titles = get_abstracts_from_papers(search_results)\n",
        "# results = run_review_pipeline(query, abstracts, titles, reference_summary)\n",
        "\n",
        "# # Print rankings\n",
        "# print(\"\\nPaper Rankings:\")\n",
        "# print(\"==============\")\n",
        "# print(\"\\nGemini Ranking:\")\n",
        "# # print(\"results!!!----------->\", results)\n",
        "# for i, idx in enumerate(results[\"rankings\"][\"gemini\"][\"ranking\"]):\n",
        "#     print(f\"{i+1}. {titles[idx-1]}\")\n",
        "\n",
        "# print(\"\\nMistral Ranking:\")\n",
        "# for i, idx in enumerate(results[\"rankings\"][\"mistral\"][\"ranking\"]):\n",
        "#     print(f\"{i+1}. {titles[idx-1]}\")\n",
        "\n",
        "# print(\"\\nEnsemble Ranking:\")\n",
        "# for i, idx in enumerate(results[\"rankings\"][\"ensemble\"][\"ranking\"]):\n",
        "#     print(f\"{i+1}. {titles[idx]} (Score: {results['rankings']['ensemble']['scores'][i]:.4f})\")\n",
        "\n",
        "# print(\"\\nFinal Ranking:\")\n",
        "# for i in (results[\"rankings\"][\"final\"]):\n",
        "#   print(f\"{i['rank']}.{i['title']} (Score: {i['relevance_score']:.4f})\")\n",
        "\n",
        "# # Print summaries (truncated for brevity)\n",
        "# print(\"\\nConsolidated Summary:\")\n",
        "# print(\"=================================\")\n",
        "# for model, summary in results[\"summaries\"].items():\n",
        "#     if summary:\n",
        "#         print(f\"\\n{model.capitalize()} Summary: {summary[:]}...\")\n",
        "\n",
        "# # Print BERT Score evaluation\n",
        "# if \"evaluation\" in results:\n",
        "#     print(\"\\nBERT Score Evaluation:\")\n",
        "#     print(\"=====================\")\n",
        "#     for model, scores in results[\"evaluation\"].items():\n",
        "#         if scores:\n",
        "#             print(f\"\\n{model.capitalize()}:\")\n",
        "#             print(f\"  Precision: {scores['precision']:.4f}\")\n",
        "#             print(f\"  Recall: {scores['recall']:.4f}\")\n",
        "#             print(f\"  F1: {scores['f1']:.4f}\")\n"
      ],
      "metadata": {
        "id": "DEL_VI6N7rqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}